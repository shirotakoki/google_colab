{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"cvae_score_v1_noconditional_fix1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7QU095PS0Fe","executionInfo":{"elapsed":466,"status":"ok","timestamp":1626104935756,"user":{"displayName":"teranosinn k","photoUrl":"","userId":"05898131523286450651"},"user_tz":-540},"outputId":"d4d0c3cb-482d-458b-ddaa-6f7df1afe43f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bp056EFxSjHr","executionInfo":{"elapsed":4,"status":"ok","timestamp":1626104935756,"user":{"displayName":"teranosinn k","photoUrl":"","userId":"05898131523286450651"},"user_tz":-540},"outputId":"5fbfbbed-7e46-43c2-e217-f1e890e1c751"},"source":["%cd /content/drive/My Drive/google_colab/music_cvae/music_cvae_notebook/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/google_colab/music_cvae/music_cvae_notebook\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"04aOu5t8PeeY"},"source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.utils.data\n","import random as rand\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from torch import FloatStorage, nn, optim\n","from torch.nn import functional as F\n","from torchvision import datasets, transforms\n","from torchvision.utils import save_image\n","from chord_v2 import chord\n","from blstm_dataset_train import my_blstm_dataset as bdtrain\n","from blstm_dataset_test import my_blstm_dataset as bdtest"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbSceVp5Tvuq","executionInfo":{"elapsed":9,"status":"ok","timestamp":1626104936287,"user":{"displayName":"teranosinn k","photoUrl":"","userId":"05898131523286450651"},"user_tz":-540},"outputId":"7d072efe-2a20-4847-c06c-7388dcd77f4c"},"source":["BATCH_SIZE = 10\n","EPOCHS = 200\n","SEQUENCE = 16\n","\n","decoders_initial_size = 32  #decoder input size\n","\n","RANDOM_SEED = 1\n","\n","cuda = not False and torch.cuda.is_available()\n","\n","torch.manual_seed(RANDOM_SEED)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f87fd771270>"]},"metadata":{"tags":[]},"execution_count":113}]},{"cell_type":"code","metadata":{"id":"0b-O7eGZ17lt"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tw0rKSJDT4Id"},"source":["train = bdtrain()\n","test = bdtrain()\n","train_loader = torch.utils.data.DataLoader(\n","    train, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(\n","    test, batch_size=2, shuffle=False)\n","\n","device = torch.device(\"cuda\" if cuda else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckoSY--_T4sF"},"source":["class VAE(nn.Module):\n","    def __init__(self,teacher_forcing = False, scheduled_sampling = False):\n","        super(VAE, self).__init__()\n","\n","        self.latent_dim = 50\n","        self.seq_dim = 16\n","        self.feature_dim = 12 + 2\n","        self.lstm_hidden_dim = 50\n","        self.input_dim = self.seq_dim*self.feature_dim\n","        self.fc0 = nn.Linear(self.input_dim, self.input_dim)\n","        self.fc_lstm1 = nn.LSTM(self.feature_dim ,self.lstm_hidden_dim,batch_first = True,bidirectional = True)\n","        self.fc1 = nn.Linear((16*self.lstm_hidden_dim*2), 150)\n","        self.fc21 = nn.Linear(self.lstm_hidden_dim*2, self.latent_dim)\n","        self.fc22 = nn.Linear(self.lstm_hidden_dim*2, self.latent_dim)\n","        self.fc3 = nn.Linear(self.latent_dim, 150)\n","        #self.fc4 = nn.Linear(150, self.input_dim)\n","        self.decoder = nn.LSTM(self.feature_dim + self.latent_dim,\n","                        self.latent_dim,\n","                        num_layers=1,\n","                        batch_first=True)\n","        #self.fc_lstm2 = nn.LSTM(self.feature_dim ,self.lstm_hidden_dim ,batch_first = True)\n","        #self.fc5 = nn.Linear(16*self.lstm_hidden_dim, self.input_dim)\n","        self.linear = nn.Linear(self.latent_dim, self.feature_dim)\n","        self.teacher_forcing = teacher_forcing\n","        self.scheduled_sampling = scheduled_sampling\n","\n","    def coinFlip(self, epoch):\n","        if (epoch-1)/EPOCHS < rand.random():\n","            return True\n","        else:\n","            return False\n","\n","    def encode(self, x):\n","        # print(x.view(-1, self.input_dim))\n","        h0 = F.relu(self.fc0(x.reshape(-1,self.input_dim)))\n","        h0 = h0.reshape(-1,self.seq_dim,self.feature_dim)\n","        f1_lstm_out, f1_lstm_h = self.fc_lstm1(h0)\n","        #f1_lstm_out = F.relu(f1_lstm_out)\n","        #print(f1_lstm_out.shape)\n","        #print(f1_lstm_h[1].shape)\n","        f1_lstm_h = torch.cat([f1_lstm_h[0][0],f1_lstm_h[0][0]],axis = 1)\n","        \"\"\"\n","        h1 = F.relu(\n","            self.fc1(f1_lstm_out.reshape(-1, 16*self.lstm_hidden_dim*2)))\n","        \"\"\"\n","        #h1 = F.relu(self.fc1(f1_lstm_h))\n","\n","        return self.fc21(f1_lstm_h), self.fc22(f1_lstm_h)\n","\n","    def decode(self, latent,x,epoch):\n","        \"\"\"\n","        h3 = F.relu(\n","            self.fc3(latent))\n","        h4 = F.relu(self.fc4(h3))        \n","        h4 = torch.t(h4).reshape(-1, self.seq_dim, self.feature_dim)\n","        h5, h5_c = self.fc_lstm2(h4)\n","        h5 = h5.reshape(-1,16*self.lstm_hidden_dim)\n","        h5 = self.fc5(h5)\n","        \"\"\"\n","        BATCH_SIZE = x.size()[0]\n","        latent = torch.reshape(latent,(BATCH_SIZE,1,-1))\n","        decoder_hidden = (torch.zeros(1,\n","                                BATCH_SIZE,\n","                                self.latent_dim,\n","                                device=device),\n","                          torch.zeros(1,\n","                                BATCH_SIZE,\n","                                self.latent_dim,\n","                                device=device))\n","        note = torch.zeros(BATCH_SIZE, 1, self.feature_dim, device=device)\n","        notes = torch.zeros(BATCH_SIZE,16,self.feature_dim, device=device)\n","        counter = 0\n","\n","        \"\"\"\n","        Todo 入力データの場合分けを行う。(Scheduled Sampling)\n","            データの入力表現が合っているか確認。\n","            ネットワークの一部を切り取って確認。\n","            小さい動く部品から組み立てていく。\n","        \"\"\"\n","        if self.scheduled_sampling:\n","            self.teacher_forcing = self.coinFlip(epoch)\n","\n","        for i in range(SEQUENCE):\n","            #print(latent.shape,note.shape)\n","\n","            e = torch.cat([latent, note], dim=-1)\n","            e = e.view(BATCH_SIZE, 1, -1)\n","\n","            # Generate a single note (for each batch)\n","            note, decoder_hidden = self.decoder(e, decoder_hidden)\n","\n","            aux = self.linear(note)\n","            aux = torch.relu(aux)\n","            # aux = torch.sigmoid(aux)\n","\n","            notes[:, counter, :] = aux.squeeze()\n","\n","            \"\"\"\n","            note = x[:,counter,:]\n","            note = torch.reshape(note, (BATCH_SIZE,1,self.feature_dim))\n","            \"\"\"\n","            if self.teacher_forcing:\n","                note = x[:,i,:].reshape(BATCH_SIZE,1,-1)\n","            else:\n","                note = aux\n","            #print(note.shape)\n","            counter = counter + 1\n","\n","        #recon_x = h5.reshape(-1, self.seq_dim, self.feature_dim)\n","        #recon_x = F.softmax(recon_x,dim=2)\n","        #print(h5.shape)\n","        notes = F.softmax(notes ,dim=2)\n","\n","        return notes\n","    \n","    def reparameterize(self, mu, logvar):\n","        std = torch.exp(0.5*logvar)\n","        eps = torch.randn_like(std)\n","        return mu + eps*std\n","\n","    def forward(self, x, epoch):\n","        x = x.float()\n","\n","        mu, logvar = self.encode(x)\n","        z = self.reparameterize(mu,logvar)\n","        return self.decode(z,x,epoch),mu, logvar"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HDFTYD3VUBym"},"source":["model = VAE(teacher_forcing=True,scheduled_sampling=True).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9jlBJBMWRwp"},"source":["# Reconstruction + KL divergence losses summed over all elements and batch\n","def loss_function(recon_x, x, mu, logvar):\n","    cd = chord()\n","    BCE = F.binary_cross_entropy(\n","        recon_x, x, reduction='sum')\n","\n","    # see Appendix B from VAE paper:\n","    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n","    # https://arxiv.org/abs/1312.6114\n","    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n","    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","\n","    \"\"\"ConsonanseLoss = F.binary_cross_entropy(cd.loss_exam(recon_x, labels),\n","                                            cd.loss_exam(x[0], labels).float().detach())\"\"\"\n","                              \n","    \"\"\"\n","    ConsonanseLoss = torch.zeros(1, requires_grad=True)\n","\n","    for i, (melody_i, chord_i, chord_type_i, consonance_i) in enumerate(zip(x, chord_d, chord_type, consonance)):\n","        ConsonanseLoss = ConsonanseLoss + (\n","            consonance_i - cd.calc_consonance_loss(melody_i, chord_i, chord_type_i).detach())**2\n","\n","    # ConsonanseLoss = ConsonanseLoss.sum()\n","    ConsonanseLoss = BCE.item()/10*ConsonanseLoss\n","    \"\"\"\n","    #print(BCE)\n","    return BCE + KLD\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxYOxbHWfP1t"},"source":["def show_params(net):\n","    for n in net.parameters():\n","        print(n)\n","\n","def show_weights(net):\n","    print(net.decoder.weight.grad)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0zzYHdsrWXw9"},"source":["def train(epoch):\n","    model.train()\n","    train_loss = 0\n","    train_consonanse_loss = 0\n","    cnt = 1\n","    for batch_idx, (melody, chord_d, chord_type) in enumerate(train_loader):\n","        # print(data.size(), labels.size())\n","        # print(labels)\n","        melody = melody.to(device)\n","        chord_d = chord_d.to(device)\n","        chord_type = chord_type.to(device)\n","        optimizer.zero_grad()\n","        recon_batch ,mu, logvar= model(melody,epoch)\n","        loss = loss_function(\n","            recon_batch, melody, mu, logvar)\n","        loss.backward()\n","        train_loss += loss.item()\n","\n","        #ネットワークパラメータを表示\n","        #show_params(model)\n","        #show_weights(model)\n","\n","        #train_consonanse_loss += consonanse_loss.item()\n","        optimizer.step()\n","\n","        if cnt % (100) == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(melody), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader),\n","                loss.item() / len(melody)))\n","        cnt += 1\n","\n","    print('====> Epoch: {} Average loss: {:.4f}'.format(\n","          epoch, train_loss / len(train_loader.dataset)))\n","    return train_loss, train_consonanse_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JoDJ5DGPWaf9"},"source":["def out_test():\n","    model.eval()\n","    model.teacher_forcing = False\n","    model.scheduled_sampling = False\n","    test_loss = 0\n","    label_flag = True\n","    with torch.no_grad():\n","        for batch_idx, (melody, chord_d, chord_type) in enumerate(test_loader):\n","            # print(data.size(), labels.size())\n","            # print(labels)\n","            melody = melody.to(device)\n","            chord_d = chord_d.to(device)\n","            chord_type = chord_type.to(device)\n","            optimizer.zero_grad()\n","            mu, logvar = model.encode(melody)\n","            z = model.reparameterize(mu, logvar)\n","            output = model.decode(z,melody,0)\n","\n","            melody = melody.to('cpu').detach().numpy().copy()\n","            output = output.to('cpu').detach().numpy().copy()\n","            melody_1 = pd.DataFrame(\n","                melody[0],\n","                columns=['c', 'c#', 'd', 'd#', 'e', 'f', 'f#', 'g', 'g#', 'a', 'a#', 'b', 'rest','hold'])\n","            output_1 = pd.DataFrame(\n","                output[0],\n","                columns=['c', 'c#', 'd', 'd#', 'e', 'f', 'f#', 'g', 'g#', 'a', 'a#', 'b', 'rest','hold'])\n","            print(z)\n","            print(melody_1)\n","            print(output_1.round(1))\n","            #output.to_csv('test_out.csv')\n","            break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"WGbQ-s79WcyE","outputId":"655090bd-86db-4f59-c41e-9faf24ea7e0a"},"source":["if __name__ == \"__main__\":\n","    train_flag = True\n","    model_path = 'models/lstm_cvae_16_noc_f.pth'\n","\n","    loss_array = np.ndarray(0)\n","    consonanse_array = np.ndarray(0)\n","    epoch_array = np.arange(1, EPOCHS+1)\n","\n","    if train_flag:\n","        for epoch in range(1, EPOCHS + 1):\n","            train_loss, train_consonanse_loss = train(epoch)\n","            loss_array = np.append(loss_array, train_loss)\n","            # consonanse_array = np.append(consonanse_array, train_consonanse_loss)\n","            # test(epoch)\n","        torch.save(model.to('cpu').state_dict(), model_path)\n","        plt.plot(np.arange(len(loss_array)),loss_array)\n","        plt.ylim(0,80)\n","        plt.show()\n","    else:\n","        model.load_state_dict(torch.load(model_path))\n","        out_test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Epoch: 1 [3168/33609 (9%)]\tLoss: 30.423521\n","Train Epoch: 1 [6368/33609 (19%)]\tLoss: 25.733898\n","Train Epoch: 1 [9568/33609 (28%)]\tLoss: 27.398254\n","Train Epoch: 1 [12768/33609 (38%)]\tLoss: 24.488396\n","Train Epoch: 1 [15968/33609 (47%)]\tLoss: 23.978668\n","Train Epoch: 1 [19168/33609 (57%)]\tLoss: 22.090374\n","Train Epoch: 1 [22368/33609 (67%)]\tLoss: 23.691168\n","Train Epoch: 1 [25568/33609 (76%)]\tLoss: 20.505037\n","Train Epoch: 1 [28768/33609 (86%)]\tLoss: 21.519194\n","Train Epoch: 1 [31968/33609 (95%)]\tLoss: 18.367821\n","====> Epoch: 1 Average loss: 24.8879\n","Train Epoch: 2 [3168/33609 (9%)]\tLoss: 21.321770\n","Train Epoch: 2 [6368/33609 (19%)]\tLoss: 21.672428\n","Train Epoch: 2 [9568/33609 (28%)]\tLoss: 18.363914\n","Train Epoch: 2 [12768/33609 (38%)]\tLoss: 21.894041\n","Train Epoch: 2 [15968/33609 (47%)]\tLoss: 17.337448\n","Train Epoch: 2 [19168/33609 (57%)]\tLoss: 17.907091\n","Train Epoch: 2 [22368/33609 (67%)]\tLoss: 19.484938\n","Train Epoch: 2 [25568/33609 (76%)]\tLoss: 21.525215\n","Train Epoch: 2 [28768/33609 (86%)]\tLoss: 17.733936\n","Train Epoch: 2 [31968/33609 (95%)]\tLoss: 18.525011\n","====> Epoch: 2 Average loss: 19.8687\n","Train Epoch: 3 [3168/33609 (9%)]\tLoss: 21.820942\n","Train Epoch: 3 [6368/33609 (19%)]\tLoss: 18.252878\n","Train Epoch: 3 [9568/33609 (28%)]\tLoss: 18.283833\n","Train Epoch: 3 [12768/33609 (38%)]\tLoss: 20.974546\n","Train Epoch: 3 [15968/33609 (47%)]\tLoss: 17.764654\n","Train Epoch: 3 [19168/33609 (57%)]\tLoss: 20.869455\n","Train Epoch: 3 [22368/33609 (67%)]\tLoss: 19.550318\n","Train Epoch: 3 [25568/33609 (76%)]\tLoss: 20.621029\n","Train Epoch: 3 [28768/33609 (86%)]\tLoss: 18.226395\n","Train Epoch: 3 [31968/33609 (95%)]\tLoss: 18.874308\n","====> Epoch: 3 Average loss: 19.1438\n","Train Epoch: 4 [3168/33609 (9%)]\tLoss: 20.038137\n","Train Epoch: 4 [6368/33609 (19%)]\tLoss: 17.088100\n","Train Epoch: 4 [9568/33609 (28%)]\tLoss: 18.568520\n","Train Epoch: 4 [12768/33609 (38%)]\tLoss: 17.299192\n","Train Epoch: 4 [15968/33609 (47%)]\tLoss: 20.675310\n","Train Epoch: 4 [19168/33609 (57%)]\tLoss: 17.352991\n","Train Epoch: 4 [22368/33609 (67%)]\tLoss: 17.851843\n","Train Epoch: 4 [25568/33609 (76%)]\tLoss: 20.640221\n","Train Epoch: 4 [28768/33609 (86%)]\tLoss: 20.684784\n","Train Epoch: 4 [31968/33609 (95%)]\tLoss: 18.812325\n","====> Epoch: 4 Average loss: 19.0912\n","Train Epoch: 5 [3168/33609 (9%)]\tLoss: 17.903351\n","Train Epoch: 5 [6368/33609 (19%)]\tLoss: 17.469675\n","Train Epoch: 5 [9568/33609 (28%)]\tLoss: 19.080751\n","Train Epoch: 5 [12768/33609 (38%)]\tLoss: 16.738836\n","Train Epoch: 5 [15968/33609 (47%)]\tLoss: 16.763321\n","Train Epoch: 5 [19168/33609 (57%)]\tLoss: 23.439831\n","Train Epoch: 5 [22368/33609 (67%)]\tLoss: 17.767317\n","Train Epoch: 5 [25568/33609 (76%)]\tLoss: 18.410044\n","Train Epoch: 5 [28768/33609 (86%)]\tLoss: 19.089954\n","Train Epoch: 5 [31968/33609 (95%)]\tLoss: 17.923153\n","====> Epoch: 5 Average loss: 19.0323\n","Train Epoch: 6 [3168/33609 (9%)]\tLoss: 18.300735\n","Train Epoch: 6 [6368/33609 (19%)]\tLoss: 18.628654\n","Train Epoch: 6 [9568/33609 (28%)]\tLoss: 19.830893\n","Train Epoch: 6 [12768/33609 (38%)]\tLoss: 19.902746\n","Train Epoch: 6 [15968/33609 (47%)]\tLoss: 18.424049\n","Train Epoch: 6 [19168/33609 (57%)]\tLoss: 17.612017\n","Train Epoch: 6 [22368/33609 (67%)]\tLoss: 18.836769\n","Train Epoch: 6 [25568/33609 (76%)]\tLoss: 19.649694\n","Train Epoch: 6 [28768/33609 (86%)]\tLoss: 18.259062\n","Train Epoch: 6 [31968/33609 (95%)]\tLoss: 19.406450\n","====> Epoch: 6 Average loss: 18.9634\n","Train Epoch: 7 [3168/33609 (9%)]\tLoss: 16.143805\n","Train Epoch: 7 [6368/33609 (19%)]\tLoss: 19.350636\n","Train Epoch: 7 [9568/33609 (28%)]\tLoss: 18.216179\n","Train Epoch: 7 [12768/33609 (38%)]\tLoss: 17.467396\n","Train Epoch: 7 [15968/33609 (47%)]\tLoss: 16.118082\n","Train Epoch: 7 [19168/33609 (57%)]\tLoss: 16.114458\n","Train Epoch: 7 [22368/33609 (67%)]\tLoss: 21.281965\n","Train Epoch: 7 [25568/33609 (76%)]\tLoss: 18.117104\n","Train Epoch: 7 [28768/33609 (86%)]\tLoss: 17.442808\n","Train Epoch: 7 [31968/33609 (95%)]\tLoss: 20.287930\n","====> Epoch: 7 Average loss: 18.8965\n","Train Epoch: 8 [3168/33609 (9%)]\tLoss: 18.023853\n","Train Epoch: 8 [6368/33609 (19%)]\tLoss: 18.120506\n","Train Epoch: 8 [9568/33609 (28%)]\tLoss: 19.190016\n","Train Epoch: 8 [12768/33609 (38%)]\tLoss: 18.316795\n","Train Epoch: 8 [15968/33609 (47%)]\tLoss: 20.041300\n","Train Epoch: 8 [19168/33609 (57%)]\tLoss: 21.435503\n","Train Epoch: 8 [22368/33609 (67%)]\tLoss: 18.690073\n","Train Epoch: 8 [25568/33609 (76%)]\tLoss: 20.042738\n","Train Epoch: 8 [28768/33609 (86%)]\tLoss: 16.842340\n","Train Epoch: 8 [31968/33609 (95%)]\tLoss: 16.882776\n","====> Epoch: 8 Average loss: 18.6841\n","Train Epoch: 9 [3168/33609 (9%)]\tLoss: 20.279703\n","Train Epoch: 9 [6368/33609 (19%)]\tLoss: 18.355394\n","Train Epoch: 9 [9568/33609 (28%)]\tLoss: 16.301155\n","Train Epoch: 9 [12768/33609 (38%)]\tLoss: 17.978527\n","Train Epoch: 9 [15968/33609 (47%)]\tLoss: 18.207621\n","Train Epoch: 9 [19168/33609 (57%)]\tLoss: 18.421721\n","Train Epoch: 9 [22368/33609 (67%)]\tLoss: 16.264021\n","Train Epoch: 9 [25568/33609 (76%)]\tLoss: 18.859354\n","Train Epoch: 9 [28768/33609 (86%)]\tLoss: 17.597216\n","Train Epoch: 9 [31968/33609 (95%)]\tLoss: 18.174467\n","====> Epoch: 9 Average loss: 18.4847\n","Train Epoch: 10 [3168/33609 (9%)]\tLoss: 18.758738\n","Train Epoch: 10 [6368/33609 (19%)]\tLoss: 16.780281\n","Train Epoch: 10 [9568/33609 (28%)]\tLoss: 14.902987\n","Train Epoch: 10 [12768/33609 (38%)]\tLoss: 18.097878\n","Train Epoch: 10 [15968/33609 (47%)]\tLoss: 19.861179\n","Train Epoch: 10 [19168/33609 (57%)]\tLoss: 18.160799\n","Train Epoch: 10 [22368/33609 (67%)]\tLoss: 21.133268\n","Train Epoch: 10 [25568/33609 (76%)]\tLoss: 17.363777\n","Train Epoch: 10 [28768/33609 (86%)]\tLoss: 16.812963\n","Train Epoch: 10 [31968/33609 (95%)]\tLoss: 19.800573\n","====> Epoch: 10 Average loss: 18.3572\n","Train Epoch: 11 [3168/33609 (9%)]\tLoss: 20.776417\n","Train Epoch: 11 [6368/33609 (19%)]\tLoss: 18.068630\n","Train Epoch: 11 [9568/33609 (28%)]\tLoss: 18.917418\n","Train Epoch: 11 [12768/33609 (38%)]\tLoss: 17.708248\n","Train Epoch: 11 [15968/33609 (47%)]\tLoss: 18.289358\n","Train Epoch: 11 [19168/33609 (57%)]\tLoss: 17.512657\n","Train Epoch: 11 [22368/33609 (67%)]\tLoss: 16.644136\n","Train Epoch: 11 [25568/33609 (76%)]\tLoss: 15.879683\n","Train Epoch: 11 [28768/33609 (86%)]\tLoss: 17.700697\n","Train Epoch: 11 [31968/33609 (95%)]\tLoss: 20.298174\n","====> Epoch: 11 Average loss: 18.2765\n","Train Epoch: 12 [3168/33609 (9%)]\tLoss: 18.148699\n","Train Epoch: 12 [6368/33609 (19%)]\tLoss: 16.720243\n","Train Epoch: 12 [9568/33609 (28%)]\tLoss: 18.507843\n","Train Epoch: 12 [12768/33609 (38%)]\tLoss: 18.588064\n","Train Epoch: 12 [15968/33609 (47%)]\tLoss: 17.672852\n","Train Epoch: 12 [19168/33609 (57%)]\tLoss: 17.389524\n","Train Epoch: 12 [22368/33609 (67%)]\tLoss: 18.578423\n","Train Epoch: 12 [25568/33609 (76%)]\tLoss: 19.292946\n","Train Epoch: 12 [28768/33609 (86%)]\tLoss: 18.924023\n","Train Epoch: 12 [31968/33609 (95%)]\tLoss: 17.195827\n","====> Epoch: 12 Average loss: 18.2299\n","Train Epoch: 13 [3168/33609 (9%)]\tLoss: 19.746939\n","Train Epoch: 13 [6368/33609 (19%)]\tLoss: 16.322977\n","Train Epoch: 13 [9568/33609 (28%)]\tLoss: 19.448994\n","Train Epoch: 13 [12768/33609 (38%)]\tLoss: 17.731834\n","Train Epoch: 13 [15968/33609 (47%)]\tLoss: 18.986822\n","Train Epoch: 13 [19168/33609 (57%)]\tLoss: 18.380896\n","Train Epoch: 13 [22368/33609 (67%)]\tLoss: 20.709734\n","Train Epoch: 13 [25568/33609 (76%)]\tLoss: 17.442335\n","Train Epoch: 13 [28768/33609 (86%)]\tLoss: 18.679153\n","Train Epoch: 13 [31968/33609 (95%)]\tLoss: 22.169079\n","====> Epoch: 13 Average loss: 18.1504\n","Train Epoch: 14 [3168/33609 (9%)]\tLoss: 19.366449\n","Train Epoch: 14 [6368/33609 (19%)]\tLoss: 14.742218\n","Train Epoch: 14 [9568/33609 (28%)]\tLoss: 17.692095\n","Train Epoch: 14 [12768/33609 (38%)]\tLoss: 20.431911\n","Train Epoch: 14 [15968/33609 (47%)]\tLoss: 16.825451\n","Train Epoch: 14 [19168/33609 (57%)]\tLoss: 19.659033\n","Train Epoch: 14 [22368/33609 (67%)]\tLoss: 17.414660\n","Train Epoch: 14 [25568/33609 (76%)]\tLoss: 18.699772\n","Train Epoch: 14 [28768/33609 (86%)]\tLoss: 18.310970\n","Train Epoch: 14 [31968/33609 (95%)]\tLoss: 15.368729\n","====> Epoch: 14 Average loss: 18.0927\n","Train Epoch: 15 [3168/33609 (9%)]\tLoss: 16.157461\n","Train Epoch: 15 [6368/33609 (19%)]\tLoss: 16.582560\n","Train Epoch: 15 [9568/33609 (28%)]\tLoss: 18.194935\n","Train Epoch: 15 [12768/33609 (38%)]\tLoss: 18.415609\n","Train Epoch: 15 [15968/33609 (47%)]\tLoss: 18.345121\n","Train Epoch: 15 [19168/33609 (57%)]\tLoss: 17.910234\n","Train Epoch: 15 [22368/33609 (67%)]\tLoss: 15.985993\n","Train Epoch: 15 [25568/33609 (76%)]\tLoss: 15.477201\n","Train Epoch: 15 [28768/33609 (86%)]\tLoss: 15.134891\n","Train Epoch: 15 [31968/33609 (95%)]\tLoss: 17.689985\n","====> Epoch: 15 Average loss: 18.0321\n","Train Epoch: 16 [3168/33609 (9%)]\tLoss: 17.964001\n","Train Epoch: 16 [6368/33609 (19%)]\tLoss: 13.803782\n","Train Epoch: 16 [9568/33609 (28%)]\tLoss: 17.527231\n","Train Epoch: 16 [12768/33609 (38%)]\tLoss: 17.028061\n","Train Epoch: 16 [15968/33609 (47%)]\tLoss: 21.129290\n","Train Epoch: 16 [19168/33609 (57%)]\tLoss: 19.936506\n","Train Epoch: 16 [22368/33609 (67%)]\tLoss: 17.029499\n","Train Epoch: 16 [25568/33609 (76%)]\tLoss: 18.037628\n","Train Epoch: 16 [28768/33609 (86%)]\tLoss: 15.503446\n","Train Epoch: 16 [31968/33609 (95%)]\tLoss: 18.790956\n","====> Epoch: 16 Average loss: 17.9947\n","Train Epoch: 17 [3168/33609 (9%)]\tLoss: 18.078215\n","Train Epoch: 17 [6368/33609 (19%)]\tLoss: 16.764261\n","Train Epoch: 17 [9568/33609 (28%)]\tLoss: 17.448120\n","Train Epoch: 17 [12768/33609 (38%)]\tLoss: 18.693069\n","Train Epoch: 17 [15968/33609 (47%)]\tLoss: 18.834883\n","Train Epoch: 17 [19168/33609 (57%)]\tLoss: 17.741680\n","Train Epoch: 17 [22368/33609 (67%)]\tLoss: 17.605658\n","Train Epoch: 17 [25568/33609 (76%)]\tLoss: 18.549818\n","Train Epoch: 17 [28768/33609 (86%)]\tLoss: 19.371031\n","Train Epoch: 17 [31968/33609 (95%)]\tLoss: 21.157896\n","====> Epoch: 17 Average loss: 17.9826\n","Train Epoch: 18 [3168/33609 (9%)]\tLoss: 18.955160\n","Train Epoch: 18 [6368/33609 (19%)]\tLoss: 17.060242\n","Train Epoch: 18 [9568/33609 (28%)]\tLoss: 20.913933\n","Train Epoch: 18 [12768/33609 (38%)]\tLoss: 18.811079\n","Train Epoch: 18 [15968/33609 (47%)]\tLoss: 18.651493\n","Train Epoch: 18 [19168/33609 (57%)]\tLoss: 18.684324\n","Train Epoch: 18 [22368/33609 (67%)]\tLoss: 18.762421\n","Train Epoch: 18 [25568/33609 (76%)]\tLoss: 16.899384\n","Train Epoch: 18 [28768/33609 (86%)]\tLoss: 18.054457\n","Train Epoch: 18 [31968/33609 (95%)]\tLoss: 16.535027\n","====> Epoch: 18 Average loss: 17.9226\n","Train Epoch: 19 [3168/33609 (9%)]\tLoss: 14.880585\n","Train Epoch: 19 [6368/33609 (19%)]\tLoss: 18.983505\n","Train Epoch: 19 [9568/33609 (28%)]\tLoss: 17.323269\n","Train Epoch: 19 [12768/33609 (38%)]\tLoss: 15.267968\n","Train Epoch: 19 [15968/33609 (47%)]\tLoss: 17.550501\n","Train Epoch: 19 [19168/33609 (57%)]\tLoss: 20.274471\n","Train Epoch: 19 [22368/33609 (67%)]\tLoss: 19.869965\n","Train Epoch: 19 [25568/33609 (76%)]\tLoss: 15.568765\n","Train Epoch: 19 [28768/33609 (86%)]\tLoss: 16.485016\n","Train Epoch: 19 [31968/33609 (95%)]\tLoss: 20.990286\n","====> Epoch: 19 Average loss: 17.9056\n","Train Epoch: 20 [3168/33609 (9%)]\tLoss: 15.392375\n","Train Epoch: 20 [6368/33609 (19%)]\tLoss: 20.225037\n","Train Epoch: 20 [9568/33609 (28%)]\tLoss: 18.887903\n","Train Epoch: 20 [12768/33609 (38%)]\tLoss: 17.558451\n","Train Epoch: 20 [15968/33609 (47%)]\tLoss: 19.343002\n","Train Epoch: 20 [19168/33609 (57%)]\tLoss: 19.012270\n","Train Epoch: 20 [22368/33609 (67%)]\tLoss: 19.499256\n","Train Epoch: 20 [25568/33609 (76%)]\tLoss: 18.486916\n","Train Epoch: 20 [28768/33609 (86%)]\tLoss: 18.346077\n","Train Epoch: 20 [31968/33609 (95%)]\tLoss: 16.902378\n","====> Epoch: 20 Average loss: 17.8542\n","Train Epoch: 21 [3168/33609 (9%)]\tLoss: 15.828541\n","Train Epoch: 21 [6368/33609 (19%)]\tLoss: 19.600372\n","Train Epoch: 21 [9568/33609 (28%)]\tLoss: 17.745127\n","Train Epoch: 21 [12768/33609 (38%)]\tLoss: 19.793907\n","Train Epoch: 21 [15968/33609 (47%)]\tLoss: 19.954021\n","Train Epoch: 21 [19168/33609 (57%)]\tLoss: 19.446880\n","Train Epoch: 21 [22368/33609 (67%)]\tLoss: 16.852634\n","Train Epoch: 21 [25568/33609 (76%)]\tLoss: 19.775230\n","Train Epoch: 21 [28768/33609 (86%)]\tLoss: 17.319769\n","Train Epoch: 21 [31968/33609 (95%)]\tLoss: 18.175865\n","====> Epoch: 21 Average loss: 17.8598\n","Train Epoch: 22 [3168/33609 (9%)]\tLoss: 15.962310\n","Train Epoch: 22 [6368/33609 (19%)]\tLoss: 18.539457\n","Train Epoch: 22 [9568/33609 (28%)]\tLoss: 17.270548\n","Train Epoch: 22 [12768/33609 (38%)]\tLoss: 16.508984\n","Train Epoch: 22 [15968/33609 (47%)]\tLoss: 19.228378\n","Train Epoch: 22 [19168/33609 (57%)]\tLoss: 18.867214\n","Train Epoch: 22 [22368/33609 (67%)]\tLoss: 16.494032\n","Train Epoch: 22 [25568/33609 (76%)]\tLoss: 20.367252\n","Train Epoch: 22 [28768/33609 (86%)]\tLoss: 15.775328\n","Train Epoch: 22 [31968/33609 (95%)]\tLoss: 18.031897\n","====> Epoch: 22 Average loss: 17.8265\n","Train Epoch: 23 [3168/33609 (9%)]\tLoss: 17.039970\n","Train Epoch: 23 [6368/33609 (19%)]\tLoss: 18.721428\n","Train Epoch: 23 [9568/33609 (28%)]\tLoss: 17.685467\n","Train Epoch: 23 [12768/33609 (38%)]\tLoss: 17.879349\n","Train Epoch: 23 [15968/33609 (47%)]\tLoss: 16.394344\n","Train Epoch: 23 [19168/33609 (57%)]\tLoss: 16.980352\n","Train Epoch: 23 [22368/33609 (67%)]\tLoss: 15.836123\n","Train Epoch: 23 [25568/33609 (76%)]\tLoss: 19.010471\n","Train Epoch: 23 [28768/33609 (86%)]\tLoss: 21.456886\n","Train Epoch: 23 [31968/33609 (95%)]\tLoss: 17.072397\n","====> Epoch: 23 Average loss: 17.8255\n","Train Epoch: 24 [3168/33609 (9%)]\tLoss: 16.717392\n","Train Epoch: 24 [6368/33609 (19%)]\tLoss: 17.967087\n","Train Epoch: 24 [9568/33609 (28%)]\tLoss: 14.981909\n","Train Epoch: 24 [12768/33609 (38%)]\tLoss: 15.751003\n","Train Epoch: 24 [15968/33609 (47%)]\tLoss: 19.982031\n","Train Epoch: 24 [19168/33609 (57%)]\tLoss: 18.839231\n","Train Epoch: 24 [22368/33609 (67%)]\tLoss: 15.690393\n","Train Epoch: 24 [25568/33609 (76%)]\tLoss: 20.346851\n","Train Epoch: 24 [28768/33609 (86%)]\tLoss: 17.701765\n","Train Epoch: 24 [31968/33609 (95%)]\tLoss: 15.506442\n","====> Epoch: 24 Average loss: 17.8107\n","Train Epoch: 25 [3168/33609 (9%)]\tLoss: 16.566677\n","Train Epoch: 25 [6368/33609 (19%)]\tLoss: 17.320059\n","Train Epoch: 25 [9568/33609 (28%)]\tLoss: 15.712675\n","Train Epoch: 25 [12768/33609 (38%)]\tLoss: 19.304829\n","Train Epoch: 25 [15968/33609 (47%)]\tLoss: 18.332355\n","Train Epoch: 25 [19168/33609 (57%)]\tLoss: 18.788267\n","Train Epoch: 25 [22368/33609 (67%)]\tLoss: 15.631606\n","Train Epoch: 25 [25568/33609 (76%)]\tLoss: 18.736017\n","Train Epoch: 25 [28768/33609 (86%)]\tLoss: 17.108908\n","Train Epoch: 25 [31968/33609 (95%)]\tLoss: 14.871082\n","====> Epoch: 25 Average loss: 17.8168\n","Train Epoch: 26 [3168/33609 (9%)]\tLoss: 17.076008\n","Train Epoch: 26 [6368/33609 (19%)]\tLoss: 18.491470\n","Train Epoch: 26 [9568/33609 (28%)]\tLoss: 17.452805\n","Train Epoch: 26 [12768/33609 (38%)]\tLoss: 17.910435\n","Train Epoch: 26 [15968/33609 (47%)]\tLoss: 17.351810\n","Train Epoch: 26 [19168/33609 (57%)]\tLoss: 15.582716\n","Train Epoch: 26 [22368/33609 (67%)]\tLoss: 18.312099\n","Train Epoch: 26 [25568/33609 (76%)]\tLoss: 16.592110\n","Train Epoch: 26 [28768/33609 (86%)]\tLoss: 17.467682\n","Train Epoch: 26 [31968/33609 (95%)]\tLoss: 20.658358\n","====> Epoch: 26 Average loss: 17.7916\n","Train Epoch: 27 [3168/33609 (9%)]\tLoss: 18.851061\n","Train Epoch: 27 [6368/33609 (19%)]\tLoss: 15.538412\n","Train Epoch: 27 [9568/33609 (28%)]\tLoss: 20.196806\n","Train Epoch: 27 [12768/33609 (38%)]\tLoss: 16.680740\n","Train Epoch: 27 [15968/33609 (47%)]\tLoss: 18.457489\n","Train Epoch: 27 [19168/33609 (57%)]\tLoss: 19.835430\n","Train Epoch: 27 [22368/33609 (67%)]\tLoss: 20.235882\n","Train Epoch: 27 [25568/33609 (76%)]\tLoss: 17.314043\n","Train Epoch: 27 [28768/33609 (86%)]\tLoss: 15.648026\n","Train Epoch: 27 [31968/33609 (95%)]\tLoss: 17.405212\n","====> Epoch: 27 Average loss: 17.7812\n","Train Epoch: 28 [3168/33609 (9%)]\tLoss: 20.712990\n","Train Epoch: 28 [6368/33609 (19%)]\tLoss: 18.763752\n","Train Epoch: 28 [9568/33609 (28%)]\tLoss: 17.001221\n","Train Epoch: 28 [12768/33609 (38%)]\tLoss: 17.392704\n","Train Epoch: 28 [15968/33609 (47%)]\tLoss: 14.500435\n","Train Epoch: 28 [19168/33609 (57%)]\tLoss: 18.474596\n","Train Epoch: 28 [22368/33609 (67%)]\tLoss: 18.475225\n","Train Epoch: 28 [25568/33609 (76%)]\tLoss: 16.493713\n","Train Epoch: 28 [28768/33609 (86%)]\tLoss: 14.410213\n","Train Epoch: 28 [31968/33609 (95%)]\tLoss: 20.350121\n","====> Epoch: 28 Average loss: 17.7145\n","Train Epoch: 29 [3168/33609 (9%)]\tLoss: 21.808157\n","Train Epoch: 29 [6368/33609 (19%)]\tLoss: 17.890371\n","Train Epoch: 29 [9568/33609 (28%)]\tLoss: 17.531363\n","Train Epoch: 29 [12768/33609 (38%)]\tLoss: 15.685156\n","Train Epoch: 29 [15968/33609 (47%)]\tLoss: 17.496216\n","Train Epoch: 29 [19168/33609 (57%)]\tLoss: 15.463348\n","Train Epoch: 29 [22368/33609 (67%)]\tLoss: 15.760172\n","Train Epoch: 29 [25568/33609 (76%)]\tLoss: 20.555889\n","Train Epoch: 29 [28768/33609 (86%)]\tLoss: 19.265823\n","Train Epoch: 29 [31968/33609 (95%)]\tLoss: 18.910698\n","====> Epoch: 29 Average loss: 17.7485\n","Train Epoch: 30 [3168/33609 (9%)]\tLoss: 17.932247\n","Train Epoch: 30 [6368/33609 (19%)]\tLoss: 17.197735\n","Train Epoch: 30 [9568/33609 (28%)]\tLoss: 17.392715\n","Train Epoch: 30 [12768/33609 (38%)]\tLoss: 17.015963\n","Train Epoch: 30 [15968/33609 (47%)]\tLoss: 17.866991\n","Train Epoch: 30 [19168/33609 (57%)]\tLoss: 17.746941\n","Train Epoch: 30 [22368/33609 (67%)]\tLoss: 15.525567\n","Train Epoch: 30 [25568/33609 (76%)]\tLoss: 17.469229\n","Train Epoch: 30 [28768/33609 (86%)]\tLoss: 16.381344\n","Train Epoch: 30 [31968/33609 (95%)]\tLoss: 17.884575\n","====> Epoch: 30 Average loss: 17.7452\n","Train Epoch: 31 [3168/33609 (9%)]\tLoss: 15.867883\n","Train Epoch: 31 [6368/33609 (19%)]\tLoss: 17.032394\n","Train Epoch: 31 [9568/33609 (28%)]\tLoss: 15.283772\n","Train Epoch: 31 [12768/33609 (38%)]\tLoss: 20.455893\n","Train Epoch: 31 [15968/33609 (47%)]\tLoss: 17.251886\n","Train Epoch: 31 [19168/33609 (57%)]\tLoss: 18.561897\n","Train Epoch: 31 [22368/33609 (67%)]\tLoss: 17.803776\n","Train Epoch: 31 [25568/33609 (76%)]\tLoss: 21.174000\n","Train Epoch: 31 [28768/33609 (86%)]\tLoss: 13.824884\n","Train Epoch: 31 [31968/33609 (95%)]\tLoss: 19.556538\n","====> Epoch: 31 Average loss: 17.6995\n","Train Epoch: 32 [3168/33609 (9%)]\tLoss: 19.112131\n","Train Epoch: 32 [6368/33609 (19%)]\tLoss: 17.581116\n","Train Epoch: 32 [9568/33609 (28%)]\tLoss: 18.103079\n","Train Epoch: 32 [12768/33609 (38%)]\tLoss: 17.965141\n","Train Epoch: 32 [15968/33609 (47%)]\tLoss: 17.831272\n","Train Epoch: 32 [19168/33609 (57%)]\tLoss: 19.859552\n","Train Epoch: 32 [22368/33609 (67%)]\tLoss: 19.174500\n","Train Epoch: 32 [25568/33609 (76%)]\tLoss: 18.166180\n","Train Epoch: 32 [28768/33609 (86%)]\tLoss: 15.610142\n","Train Epoch: 32 [31968/33609 (95%)]\tLoss: 17.594196\n","====> Epoch: 32 Average loss: 17.6752\n","Train Epoch: 33 [3168/33609 (9%)]\tLoss: 16.813540\n","Train Epoch: 33 [6368/33609 (19%)]\tLoss: 18.476471\n","Train Epoch: 33 [9568/33609 (28%)]\tLoss: 16.905485\n","Train Epoch: 33 [12768/33609 (38%)]\tLoss: 16.293964\n","Train Epoch: 33 [15968/33609 (47%)]\tLoss: 16.648729\n","Train Epoch: 33 [19168/33609 (57%)]\tLoss: 15.010193\n","Train Epoch: 33 [22368/33609 (67%)]\tLoss: 17.842392\n","Train Epoch: 33 [25568/33609 (76%)]\tLoss: 16.396399\n","Train Epoch: 33 [28768/33609 (86%)]\tLoss: 15.966905\n","Train Epoch: 33 [31968/33609 (95%)]\tLoss: 21.267332\n","====> Epoch: 33 Average loss: 17.6751\n","Train Epoch: 34 [3168/33609 (9%)]\tLoss: 19.442532\n","Train Epoch: 34 [6368/33609 (19%)]\tLoss: 16.520634\n","Train Epoch: 34 [9568/33609 (28%)]\tLoss: 17.817919\n","Train Epoch: 34 [12768/33609 (38%)]\tLoss: 15.573126\n","Train Epoch: 34 [15968/33609 (47%)]\tLoss: 17.600908\n","Train Epoch: 34 [19168/33609 (57%)]\tLoss: 18.395891\n","Train Epoch: 34 [22368/33609 (67%)]\tLoss: 16.292759\n","Train Epoch: 34 [25568/33609 (76%)]\tLoss: 19.044027\n","Train Epoch: 34 [28768/33609 (86%)]\tLoss: 20.440174\n","Train Epoch: 34 [31968/33609 (95%)]\tLoss: 16.692839\n","====> Epoch: 34 Average loss: 17.8202\n","Train Epoch: 35 [3168/33609 (9%)]\tLoss: 18.881578\n","Train Epoch: 35 [6368/33609 (19%)]\tLoss: 18.920650\n","Train Epoch: 35 [9568/33609 (28%)]\tLoss: 18.022326\n","Train Epoch: 35 [12768/33609 (38%)]\tLoss: 16.320688\n","Train Epoch: 35 [15968/33609 (47%)]\tLoss: 17.648663\n","Train Epoch: 35 [19168/33609 (57%)]\tLoss: 18.635590\n","Train Epoch: 35 [22368/33609 (67%)]\tLoss: 18.205688\n","Train Epoch: 35 [25568/33609 (76%)]\tLoss: 17.734741\n","Train Epoch: 35 [28768/33609 (86%)]\tLoss: 16.501112\n","Train Epoch: 35 [31968/33609 (95%)]\tLoss: 18.732992\n","====> Epoch: 35 Average loss: 17.7048\n","Train Epoch: 36 [3168/33609 (9%)]\tLoss: 18.636732\n","Train Epoch: 36 [6368/33609 (19%)]\tLoss: 19.508003\n","Train Epoch: 36 [9568/33609 (28%)]\tLoss: 18.998287\n","Train Epoch: 36 [12768/33609 (38%)]\tLoss: 18.169750\n","Train Epoch: 36 [15968/33609 (47%)]\tLoss: 16.426441\n","Train Epoch: 36 [19168/33609 (57%)]\tLoss: 16.073006\n","Train Epoch: 36 [22368/33609 (67%)]\tLoss: 17.183598\n","Train Epoch: 36 [25568/33609 (76%)]\tLoss: 19.448660\n","Train Epoch: 36 [28768/33609 (86%)]\tLoss: 17.774813\n","Train Epoch: 36 [31968/33609 (95%)]\tLoss: 16.379492\n","====> Epoch: 36 Average loss: 17.6829\n","Train Epoch: 37 [3168/33609 (9%)]\tLoss: 16.638683\n","Train Epoch: 37 [6368/33609 (19%)]\tLoss: 16.055458\n","Train Epoch: 37 [9568/33609 (28%)]\tLoss: 20.811954\n","Train Epoch: 37 [12768/33609 (38%)]\tLoss: 19.952679\n","Train Epoch: 37 [15968/33609 (47%)]\tLoss: 14.233354\n","Train Epoch: 37 [19168/33609 (57%)]\tLoss: 20.312981\n","Train Epoch: 37 [22368/33609 (67%)]\tLoss: 19.711983\n","Train Epoch: 37 [25568/33609 (76%)]\tLoss: 19.031799\n","Train Epoch: 37 [28768/33609 (86%)]\tLoss: 17.727303\n","Train Epoch: 37 [31968/33609 (95%)]\tLoss: 16.265934\n","====> Epoch: 37 Average loss: 17.6715\n","Train Epoch: 38 [3168/33609 (9%)]\tLoss: 16.141928\n","Train Epoch: 38 [6368/33609 (19%)]\tLoss: 15.620060\n","Train Epoch: 38 [9568/33609 (28%)]\tLoss: 15.725924\n","Train Epoch: 38 [12768/33609 (38%)]\tLoss: 17.626537\n","Train Epoch: 38 [15968/33609 (47%)]\tLoss: 19.138672\n","Train Epoch: 38 [19168/33609 (57%)]\tLoss: 13.758214\n","Train Epoch: 38 [22368/33609 (67%)]\tLoss: 19.655333\n","Train Epoch: 38 [25568/33609 (76%)]\tLoss: 18.346632\n","Train Epoch: 38 [28768/33609 (86%)]\tLoss: 14.736389\n","Train Epoch: 38 [31968/33609 (95%)]\tLoss: 17.704412\n","====> Epoch: 38 Average loss: 17.6579\n","Train Epoch: 39 [3168/33609 (9%)]\tLoss: 17.581310\n","Train Epoch: 39 [6368/33609 (19%)]\tLoss: 19.177689\n","Train Epoch: 39 [9568/33609 (28%)]\tLoss: 17.910812\n","Train Epoch: 39 [12768/33609 (38%)]\tLoss: 19.077890\n","Train Epoch: 39 [15968/33609 (47%)]\tLoss: 15.569674\n","Train Epoch: 39 [19168/33609 (57%)]\tLoss: 17.668295\n","Train Epoch: 39 [22368/33609 (67%)]\tLoss: 18.147041\n","Train Epoch: 39 [25568/33609 (76%)]\tLoss: 17.851456\n","Train Epoch: 39 [28768/33609 (86%)]\tLoss: 17.383699\n","Train Epoch: 39 [31968/33609 (95%)]\tLoss: 16.493635\n","====> Epoch: 39 Average loss: 17.6474\n","Train Epoch: 40 [3168/33609 (9%)]\tLoss: 17.769293\n","Train Epoch: 40 [6368/33609 (19%)]\tLoss: 17.365118\n","Train Epoch: 40 [9568/33609 (28%)]\tLoss: 15.843047\n","Train Epoch: 40 [12768/33609 (38%)]\tLoss: 19.216188\n","Train Epoch: 40 [15968/33609 (47%)]\tLoss: 15.652489\n","Train Epoch: 40 [19168/33609 (57%)]\tLoss: 15.296278\n","Train Epoch: 40 [22368/33609 (67%)]\tLoss: 16.388729\n","Train Epoch: 40 [25568/33609 (76%)]\tLoss: 18.360008\n","Train Epoch: 40 [28768/33609 (86%)]\tLoss: 19.711622\n","Train Epoch: 40 [31968/33609 (95%)]\tLoss: 20.064938\n","====> Epoch: 40 Average loss: 17.6274\n","Train Epoch: 41 [3168/33609 (9%)]\tLoss: 20.885208\n","Train Epoch: 41 [6368/33609 (19%)]\tLoss: 18.280043\n","Train Epoch: 41 [9568/33609 (28%)]\tLoss: 19.110117\n","Train Epoch: 41 [12768/33609 (38%)]\tLoss: 18.324455\n","Train Epoch: 41 [15968/33609 (47%)]\tLoss: 15.523173\n","Train Epoch: 41 [19168/33609 (57%)]\tLoss: 15.795453\n","Train Epoch: 41 [22368/33609 (67%)]\tLoss: 19.424646\n","Train Epoch: 41 [25568/33609 (76%)]\tLoss: 15.250109\n","Train Epoch: 41 [28768/33609 (86%)]\tLoss: 18.875267\n","Train Epoch: 41 [31968/33609 (95%)]\tLoss: 16.280521\n","====> Epoch: 41 Average loss: 17.6235\n","Train Epoch: 42 [3168/33609 (9%)]\tLoss: 17.950142\n","Train Epoch: 42 [6368/33609 (19%)]\tLoss: 16.935505\n","Train Epoch: 42 [9568/33609 (28%)]\tLoss: 15.345792\n","Train Epoch: 42 [12768/33609 (38%)]\tLoss: 16.780123\n","Train Epoch: 42 [15968/33609 (47%)]\tLoss: 15.111734\n","Train Epoch: 42 [19168/33609 (57%)]\tLoss: 18.109390\n","Train Epoch: 42 [22368/33609 (67%)]\tLoss: 18.131626\n","Train Epoch: 42 [25568/33609 (76%)]\tLoss: 17.964073\n","Train Epoch: 42 [28768/33609 (86%)]\tLoss: 18.151243\n","Train Epoch: 42 [31968/33609 (95%)]\tLoss: 17.736923\n","====> Epoch: 42 Average loss: 17.6435\n","Train Epoch: 43 [3168/33609 (9%)]\tLoss: 16.896574\n","Train Epoch: 43 [6368/33609 (19%)]\tLoss: 17.753967\n","Train Epoch: 43 [9568/33609 (28%)]\tLoss: 18.860867\n","Train Epoch: 43 [12768/33609 (38%)]\tLoss: 17.680214\n","Train Epoch: 43 [15968/33609 (47%)]\tLoss: 19.356125\n","Train Epoch: 43 [19168/33609 (57%)]\tLoss: 19.723831\n","Train Epoch: 43 [22368/33609 (67%)]\tLoss: 13.781171\n","Train Epoch: 43 [25568/33609 (76%)]\tLoss: 14.850066\n","Train Epoch: 43 [28768/33609 (86%)]\tLoss: 16.398415\n","Train Epoch: 43 [31968/33609 (95%)]\tLoss: 18.552299\n","====> Epoch: 43 Average loss: 17.6036\n","Train Epoch: 44 [3168/33609 (9%)]\tLoss: 16.325720\n","Train Epoch: 44 [6368/33609 (19%)]\tLoss: 17.934355\n","Train Epoch: 44 [9568/33609 (28%)]\tLoss: 14.891843\n","Train Epoch: 44 [12768/33609 (38%)]\tLoss: 19.815205\n","Train Epoch: 44 [15968/33609 (47%)]\tLoss: 18.033197\n","Train Epoch: 44 [19168/33609 (57%)]\tLoss: 16.795006\n","Train Epoch: 44 [22368/33609 (67%)]\tLoss: 17.416681\n","Train Epoch: 44 [25568/33609 (76%)]\tLoss: 17.654633\n","Train Epoch: 44 [28768/33609 (86%)]\tLoss: 16.753490\n","Train Epoch: 44 [31968/33609 (95%)]\tLoss: 17.422440\n","====> Epoch: 44 Average loss: 17.6353\n","Train Epoch: 45 [3168/33609 (9%)]\tLoss: 16.856789\n","Train Epoch: 45 [6368/33609 (19%)]\tLoss: 16.244217\n","Train Epoch: 45 [9568/33609 (28%)]\tLoss: 13.718118\n","Train Epoch: 45 [12768/33609 (38%)]\tLoss: 19.805923\n","Train Epoch: 45 [15968/33609 (47%)]\tLoss: 18.166758\n","Train Epoch: 45 [19168/33609 (57%)]\tLoss: 18.218737\n","Train Epoch: 45 [22368/33609 (67%)]\tLoss: 18.314714\n","Train Epoch: 45 [25568/33609 (76%)]\tLoss: 20.497105\n","Train Epoch: 45 [28768/33609 (86%)]\tLoss: 15.820504\n","Train Epoch: 45 [31968/33609 (95%)]\tLoss: 18.086622\n","====> Epoch: 45 Average loss: 17.6318\n","Train Epoch: 46 [3168/33609 (9%)]\tLoss: 16.834881\n","Train Epoch: 46 [6368/33609 (19%)]\tLoss: 17.336792\n","Train Epoch: 46 [9568/33609 (28%)]\tLoss: 20.516500\n","Train Epoch: 46 [12768/33609 (38%)]\tLoss: 16.040142\n","Train Epoch: 46 [15968/33609 (47%)]\tLoss: 18.357365\n","Train Epoch: 46 [19168/33609 (57%)]\tLoss: 20.828873\n","Train Epoch: 46 [22368/33609 (67%)]\tLoss: 14.231198\n","Train Epoch: 46 [25568/33609 (76%)]\tLoss: 16.266176\n","Train Epoch: 46 [28768/33609 (86%)]\tLoss: 17.637264\n","Train Epoch: 46 [31968/33609 (95%)]\tLoss: 18.267254\n","====> Epoch: 46 Average loss: 17.6038\n","Train Epoch: 47 [3168/33609 (9%)]\tLoss: 19.374607\n","Train Epoch: 47 [6368/33609 (19%)]\tLoss: 17.377146\n","Train Epoch: 47 [9568/33609 (28%)]\tLoss: 18.156301\n","Train Epoch: 47 [12768/33609 (38%)]\tLoss: 13.554360\n","Train Epoch: 47 [15968/33609 (47%)]\tLoss: 20.704023\n","Train Epoch: 47 [19168/33609 (57%)]\tLoss: 15.604002\n","Train Epoch: 47 [22368/33609 (67%)]\tLoss: 17.603348\n","Train Epoch: 47 [25568/33609 (76%)]\tLoss: 17.870029\n","Train Epoch: 47 [28768/33609 (86%)]\tLoss: 21.107639\n","Train Epoch: 47 [31968/33609 (95%)]\tLoss: 14.615007\n","====> Epoch: 47 Average loss: 17.6027\n","Train Epoch: 48 [3168/33609 (9%)]\tLoss: 16.896475\n","Train Epoch: 48 [6368/33609 (19%)]\tLoss: 17.937218\n","Train Epoch: 48 [9568/33609 (28%)]\tLoss: 17.709326\n","Train Epoch: 48 [12768/33609 (38%)]\tLoss: 19.987003\n","Train Epoch: 48 [15968/33609 (47%)]\tLoss: 16.980728\n","Train Epoch: 48 [19168/33609 (57%)]\tLoss: 17.048708\n","Train Epoch: 48 [22368/33609 (67%)]\tLoss: 18.952988\n","Train Epoch: 48 [25568/33609 (76%)]\tLoss: 18.081127\n","Train Epoch: 48 [28768/33609 (86%)]\tLoss: 19.909290\n","Train Epoch: 48 [31968/33609 (95%)]\tLoss: 16.581930\n","====> Epoch: 48 Average loss: 17.5961\n","Train Epoch: 49 [3168/33609 (9%)]\tLoss: 17.227457\n","Train Epoch: 49 [6368/33609 (19%)]\tLoss: 14.718739\n","Train Epoch: 49 [9568/33609 (28%)]\tLoss: 17.570801\n","Train Epoch: 49 [12768/33609 (38%)]\tLoss: 19.231657\n","Train Epoch: 49 [15968/33609 (47%)]\tLoss: 17.643476\n","Train Epoch: 49 [19168/33609 (57%)]\tLoss: 15.832850\n","Train Epoch: 49 [22368/33609 (67%)]\tLoss: 19.257994\n","Train Epoch: 49 [25568/33609 (76%)]\tLoss: 15.631205\n","Train Epoch: 49 [28768/33609 (86%)]\tLoss: 14.864966\n","Train Epoch: 49 [31968/33609 (95%)]\tLoss: 15.545679\n","====> Epoch: 49 Average loss: 17.6364\n","Train Epoch: 50 [3168/33609 (9%)]\tLoss: 20.342840\n","Train Epoch: 50 [6368/33609 (19%)]\tLoss: 18.671854\n","Train Epoch: 50 [9568/33609 (28%)]\tLoss: 21.015808\n","Train Epoch: 50 [12768/33609 (38%)]\tLoss: 22.321796\n","Train Epoch: 50 [15968/33609 (47%)]\tLoss: 23.843845\n","Train Epoch: 50 [19168/33609 (57%)]\tLoss: 20.518520\n","Train Epoch: 50 [22368/33609 (67%)]\tLoss: 19.486774\n","Train Epoch: 50 [25568/33609 (76%)]\tLoss: 17.460470\n","Train Epoch: 50 [28768/33609 (86%)]\tLoss: 18.433659\n","Train Epoch: 50 [31968/33609 (95%)]\tLoss: 16.434200\n","====> Epoch: 50 Average loss: 19.3139\n","Train Epoch: 51 [3168/33609 (9%)]\tLoss: 18.550264\n","Train Epoch: 51 [6368/33609 (19%)]\tLoss: 19.089579\n","Train Epoch: 51 [9568/33609 (28%)]\tLoss: 16.047173\n","Train Epoch: 51 [12768/33609 (38%)]\tLoss: 20.928493\n","Train Epoch: 51 [15968/33609 (47%)]\tLoss: 17.760809\n","Train Epoch: 51 [19168/33609 (57%)]\tLoss: 18.529619\n","Train Epoch: 51 [22368/33609 (67%)]\tLoss: 17.952009\n","Train Epoch: 51 [25568/33609 (76%)]\tLoss: 16.138195\n","Train Epoch: 51 [28768/33609 (86%)]\tLoss: 18.806347\n","Train Epoch: 51 [31968/33609 (95%)]\tLoss: 15.902070\n","====> Epoch: 51 Average loss: 18.3068\n","Train Epoch: 52 [3168/33609 (9%)]\tLoss: 18.300182\n","Train Epoch: 52 [6368/33609 (19%)]\tLoss: 17.584810\n","Train Epoch: 52 [9568/33609 (28%)]\tLoss: 20.408518\n","Train Epoch: 52 [12768/33609 (38%)]\tLoss: 17.120548\n","Train Epoch: 52 [15968/33609 (47%)]\tLoss: 19.027250\n","Train Epoch: 52 [19168/33609 (57%)]\tLoss: 18.352093\n","Train Epoch: 52 [22368/33609 (67%)]\tLoss: 17.055801\n","Train Epoch: 52 [25568/33609 (76%)]\tLoss: 18.875183\n","Train Epoch: 52 [28768/33609 (86%)]\tLoss: 16.874111\n","Train Epoch: 52 [31968/33609 (95%)]\tLoss: 17.858200\n","====> Epoch: 52 Average loss: 18.0156\n","Train Epoch: 53 [3168/33609 (9%)]\tLoss: 17.216356\n","Train Epoch: 53 [6368/33609 (19%)]\tLoss: 19.521078\n","Train Epoch: 53 [9568/33609 (28%)]\tLoss: 17.505211\n","Train Epoch: 53 [12768/33609 (38%)]\tLoss: 19.510674\n","Train Epoch: 53 [15968/33609 (47%)]\tLoss: 18.638248\n","Train Epoch: 53 [19168/33609 (57%)]\tLoss: 18.732849\n","Train Epoch: 53 [22368/33609 (67%)]\tLoss: 16.990700\n","Train Epoch: 53 [25568/33609 (76%)]\tLoss: 19.666096\n","Train Epoch: 53 [28768/33609 (86%)]\tLoss: 16.959206\n","Train Epoch: 53 [31968/33609 (95%)]\tLoss: 16.365116\n","====> Epoch: 53 Average loss: 17.8669\n","Train Epoch: 54 [3168/33609 (9%)]\tLoss: 17.988270\n","Train Epoch: 54 [6368/33609 (19%)]\tLoss: 19.157290\n","Train Epoch: 54 [9568/33609 (28%)]\tLoss: 18.651367\n","Train Epoch: 54 [12768/33609 (38%)]\tLoss: 17.713829\n","Train Epoch: 54 [15968/33609 (47%)]\tLoss: 15.504455\n","Train Epoch: 54 [19168/33609 (57%)]\tLoss: 16.557674\n","Train Epoch: 54 [22368/33609 (67%)]\tLoss: 17.977890\n","Train Epoch: 54 [25568/33609 (76%)]\tLoss: 17.765200\n","Train Epoch: 54 [28768/33609 (86%)]\tLoss: 17.997463\n","Train Epoch: 54 [31968/33609 (95%)]\tLoss: 17.153288\n","====> Epoch: 54 Average loss: 17.7816\n","Train Epoch: 55 [3168/33609 (9%)]\tLoss: 18.077671\n","Train Epoch: 55 [6368/33609 (19%)]\tLoss: 16.966774\n","Train Epoch: 55 [9568/33609 (28%)]\tLoss: 17.440039\n","Train Epoch: 55 [12768/33609 (38%)]\tLoss: 17.192150\n","Train Epoch: 55 [15968/33609 (47%)]\tLoss: 16.986515\n","Train Epoch: 55 [19168/33609 (57%)]\tLoss: 14.620522\n","Train Epoch: 55 [22368/33609 (67%)]\tLoss: 15.038391\n","Train Epoch: 55 [25568/33609 (76%)]\tLoss: 14.850962\n","Train Epoch: 55 [28768/33609 (86%)]\tLoss: 17.298161\n","Train Epoch: 55 [31968/33609 (95%)]\tLoss: 18.167511\n","====> Epoch: 55 Average loss: 17.7007\n","Train Epoch: 56 [3168/33609 (9%)]\tLoss: 20.418163\n","Train Epoch: 56 [6368/33609 (19%)]\tLoss: 19.791861\n","Train Epoch: 56 [9568/33609 (28%)]\tLoss: 16.549131\n","Train Epoch: 56 [12768/33609 (38%)]\tLoss: 19.183088\n","Train Epoch: 56 [15968/33609 (47%)]\tLoss: 18.058586\n","Train Epoch: 56 [19168/33609 (57%)]\tLoss: 17.601965\n","Train Epoch: 56 [22368/33609 (67%)]\tLoss: 18.997314\n","Train Epoch: 56 [25568/33609 (76%)]\tLoss: 18.096418\n","Train Epoch: 56 [28768/33609 (86%)]\tLoss: 18.805639\n","Train Epoch: 56 [31968/33609 (95%)]\tLoss: 15.879742\n","====> Epoch: 56 Average loss: 17.6317\n","Train Epoch: 57 [3168/33609 (9%)]\tLoss: 21.876015\n","Train Epoch: 57 [6368/33609 (19%)]\tLoss: 19.584303\n","Train Epoch: 57 [9568/33609 (28%)]\tLoss: 17.694653\n","Train Epoch: 57 [12768/33609 (38%)]\tLoss: 18.155544\n","Train Epoch: 57 [15968/33609 (47%)]\tLoss: 16.575424\n","Train Epoch: 57 [19168/33609 (57%)]\tLoss: 18.136190\n","Train Epoch: 57 [22368/33609 (67%)]\tLoss: 19.171759\n","Train Epoch: 57 [25568/33609 (76%)]\tLoss: 16.789223\n","Train Epoch: 57 [28768/33609 (86%)]\tLoss: 16.262356\n","Train Epoch: 57 [31968/33609 (95%)]\tLoss: 16.799593\n","====> Epoch: 57 Average loss: 17.6394\n","Train Epoch: 58 [3168/33609 (9%)]\tLoss: 16.928230\n","Train Epoch: 58 [6368/33609 (19%)]\tLoss: 16.969395\n","Train Epoch: 58 [9568/33609 (28%)]\tLoss: 15.217773\n","Train Epoch: 58 [12768/33609 (38%)]\tLoss: 15.874969\n","Train Epoch: 58 [15968/33609 (47%)]\tLoss: 18.800360\n","Train Epoch: 58 [19168/33609 (57%)]\tLoss: 17.746195\n","Train Epoch: 58 [22368/33609 (67%)]\tLoss: 16.159485\n","Train Epoch: 58 [25568/33609 (76%)]\tLoss: 15.307970\n","Train Epoch: 58 [28768/33609 (86%)]\tLoss: 17.504324\n","Train Epoch: 58 [31968/33609 (95%)]\tLoss: 16.754232\n","====> Epoch: 58 Average loss: 17.6532\n","Train Epoch: 59 [3168/33609 (9%)]\tLoss: 15.968353\n","Train Epoch: 59 [6368/33609 (19%)]\tLoss: 15.581736\n","Train Epoch: 59 [9568/33609 (28%)]\tLoss: 17.617395\n","Train Epoch: 59 [12768/33609 (38%)]\tLoss: 14.048175\n","Train Epoch: 59 [15968/33609 (47%)]\tLoss: 16.946142\n","Train Epoch: 59 [19168/33609 (57%)]\tLoss: 17.662374\n","Train Epoch: 59 [22368/33609 (67%)]\tLoss: 16.576347\n","Train Epoch: 59 [25568/33609 (76%)]\tLoss: 20.514162\n","Train Epoch: 59 [28768/33609 (86%)]\tLoss: 16.005070\n","Train Epoch: 59 [31968/33609 (95%)]\tLoss: 18.496229\n","====> Epoch: 59 Average loss: 17.6459\n","Train Epoch: 60 [3168/33609 (9%)]\tLoss: 18.855181\n","Train Epoch: 60 [6368/33609 (19%)]\tLoss: 16.880692\n","Train Epoch: 60 [9568/33609 (28%)]\tLoss: 15.295176\n","Train Epoch: 60 [12768/33609 (38%)]\tLoss: 18.011040\n","Train Epoch: 60 [15968/33609 (47%)]\tLoss: 22.874434\n","Train Epoch: 60 [19168/33609 (57%)]\tLoss: 15.600436\n","Train Epoch: 60 [22368/33609 (67%)]\tLoss: 17.820786\n","Train Epoch: 60 [25568/33609 (76%)]\tLoss: 15.786658\n","Train Epoch: 60 [28768/33609 (86%)]\tLoss: 16.189758\n","Train Epoch: 60 [31968/33609 (95%)]\tLoss: 21.332188\n","====> Epoch: 60 Average loss: 17.6163\n","Train Epoch: 61 [3168/33609 (9%)]\tLoss: 15.502153\n","Train Epoch: 61 [6368/33609 (19%)]\tLoss: 18.671093\n","Train Epoch: 61 [9568/33609 (28%)]\tLoss: 16.802010\n","Train Epoch: 61 [12768/33609 (38%)]\tLoss: 17.828499\n","Train Epoch: 61 [15968/33609 (47%)]\tLoss: 16.661558\n","Train Epoch: 61 [19168/33609 (57%)]\tLoss: 19.256676\n","Train Epoch: 61 [22368/33609 (67%)]\tLoss: 17.559410\n","Train Epoch: 61 [25568/33609 (76%)]\tLoss: 16.787470\n","Train Epoch: 61 [28768/33609 (86%)]\tLoss: 17.829166\n","Train Epoch: 61 [31968/33609 (95%)]\tLoss: 16.262295\n","====> Epoch: 61 Average loss: 17.6139\n","Train Epoch: 62 [3168/33609 (9%)]\tLoss: 17.114361\n","Train Epoch: 62 [6368/33609 (19%)]\tLoss: 17.425339\n","Train Epoch: 62 [9568/33609 (28%)]\tLoss: 15.398110\n","Train Epoch: 62 [12768/33609 (38%)]\tLoss: 20.248020\n","Train Epoch: 62 [15968/33609 (47%)]\tLoss: 16.656942\n","Train Epoch: 62 [19168/33609 (57%)]\tLoss: 18.290598\n","Train Epoch: 62 [22368/33609 (67%)]\tLoss: 17.984667\n","Train Epoch: 62 [25568/33609 (76%)]\tLoss: 20.047171\n","Train Epoch: 62 [28768/33609 (86%)]\tLoss: 15.039205\n","Train Epoch: 62 [31968/33609 (95%)]\tLoss: 16.658213\n","====> Epoch: 62 Average loss: 17.6188\n","Train Epoch: 63 [3168/33609 (9%)]\tLoss: 17.963972\n","Train Epoch: 63 [6368/33609 (19%)]\tLoss: 15.148170\n","Train Epoch: 63 [9568/33609 (28%)]\tLoss: 15.121052\n","Train Epoch: 63 [12768/33609 (38%)]\tLoss: 19.600946\n","Train Epoch: 63 [15968/33609 (47%)]\tLoss: 18.643755\n","Train Epoch: 63 [19168/33609 (57%)]\tLoss: 16.182020\n","Train Epoch: 63 [22368/33609 (67%)]\tLoss: 14.282093\n","Train Epoch: 63 [25568/33609 (76%)]\tLoss: 19.010588\n","Train Epoch: 63 [28768/33609 (86%)]\tLoss: 16.427277\n","Train Epoch: 63 [31968/33609 (95%)]\tLoss: 19.846603\n","====> Epoch: 63 Average loss: 17.6098\n","Train Epoch: 64 [3168/33609 (9%)]\tLoss: 19.891304\n","Train Epoch: 64 [6368/33609 (19%)]\tLoss: 18.101450\n","Train Epoch: 64 [9568/33609 (28%)]\tLoss: 18.203781\n","Train Epoch: 64 [12768/33609 (38%)]\tLoss: 20.465178\n","Train Epoch: 64 [15968/33609 (47%)]\tLoss: 19.514507\n","Train Epoch: 64 [19168/33609 (57%)]\tLoss: 15.596045\n","Train Epoch: 64 [22368/33609 (67%)]\tLoss: 20.193546\n","Train Epoch: 64 [25568/33609 (76%)]\tLoss: 17.031788\n","Train Epoch: 64 [28768/33609 (86%)]\tLoss: 17.091089\n","Train Epoch: 64 [31968/33609 (95%)]\tLoss: 15.314249\n","====> Epoch: 64 Average loss: 17.6123\n","Train Epoch: 65 [3168/33609 (9%)]\tLoss: 14.888999\n","Train Epoch: 65 [6368/33609 (19%)]\tLoss: 14.624430\n","Train Epoch: 65 [9568/33609 (28%)]\tLoss: 17.390717\n","Train Epoch: 65 [12768/33609 (38%)]\tLoss: 16.414665\n","Train Epoch: 65 [15968/33609 (47%)]\tLoss: 17.096924\n","Train Epoch: 65 [19168/33609 (57%)]\tLoss: 19.275074\n","Train Epoch: 65 [22368/33609 (67%)]\tLoss: 20.894564\n","Train Epoch: 65 [25568/33609 (76%)]\tLoss: 14.568912\n","Train Epoch: 65 [28768/33609 (86%)]\tLoss: 19.800798\n","Train Epoch: 65 [31968/33609 (95%)]\tLoss: 17.489046\n","====> Epoch: 65 Average loss: 17.5904\n","Train Epoch: 66 [3168/33609 (9%)]\tLoss: 18.108347\n","Train Epoch: 66 [6368/33609 (19%)]\tLoss: 15.084862\n","Train Epoch: 66 [9568/33609 (28%)]\tLoss: 14.721918\n","Train Epoch: 66 [12768/33609 (38%)]\tLoss: 15.961414\n","Train Epoch: 66 [15968/33609 (47%)]\tLoss: 17.252857\n","Train Epoch: 66 [19168/33609 (57%)]\tLoss: 14.602789\n","Train Epoch: 66 [22368/33609 (67%)]\tLoss: 15.651165\n","Train Epoch: 66 [25568/33609 (76%)]\tLoss: 16.651901\n","Train Epoch: 66 [28768/33609 (86%)]\tLoss: 19.818542\n","Train Epoch: 66 [31968/33609 (95%)]\tLoss: 14.551307\n","====> Epoch: 66 Average loss: 17.5948\n","Train Epoch: 67 [3168/33609 (9%)]\tLoss: 16.775261\n","Train Epoch: 67 [6368/33609 (19%)]\tLoss: 17.693462\n","Train Epoch: 67 [9568/33609 (28%)]\tLoss: 19.642677\n","Train Epoch: 67 [12768/33609 (38%)]\tLoss: 14.542667\n","Train Epoch: 67 [15968/33609 (47%)]\tLoss: 19.513857\n","Train Epoch: 67 [19168/33609 (57%)]\tLoss: 30.633213\n","Train Epoch: 67 [22368/33609 (67%)]\tLoss: 25.285961\n","Train Epoch: 67 [25568/33609 (76%)]\tLoss: 21.127903\n","Train Epoch: 67 [28768/33609 (86%)]\tLoss: 27.696938\n","Train Epoch: 67 [31968/33609 (95%)]\tLoss: 24.079012\n","====> Epoch: 67 Average loss: 21.0568\n","Train Epoch: 68 [3168/33609 (9%)]\tLoss: 20.508011\n","Train Epoch: 68 [6368/33609 (19%)]\tLoss: 20.351173\n","Train Epoch: 68 [9568/33609 (28%)]\tLoss: 20.685753\n","Train Epoch: 68 [12768/33609 (38%)]\tLoss: 22.583427\n","Train Epoch: 68 [15968/33609 (47%)]\tLoss: 17.073505\n","Train Epoch: 68 [19168/33609 (57%)]\tLoss: 18.484453\n","Train Epoch: 68 [22368/33609 (67%)]\tLoss: 18.847305\n","Train Epoch: 68 [25568/33609 (76%)]\tLoss: 18.537174\n","Train Epoch: 68 [28768/33609 (86%)]\tLoss: 17.924067\n","Train Epoch: 68 [31968/33609 (95%)]\tLoss: 18.045015\n","====> Epoch: 68 Average loss: 20.6232\n","Train Epoch: 69 [3168/33609 (9%)]\tLoss: 17.742702\n","Train Epoch: 69 [6368/33609 (19%)]\tLoss: 17.045490\n","Train Epoch: 69 [9568/33609 (28%)]\tLoss: 20.968599\n","Train Epoch: 69 [12768/33609 (38%)]\tLoss: 19.452173\n","Train Epoch: 69 [15968/33609 (47%)]\tLoss: 18.982491\n","Train Epoch: 69 [19168/33609 (57%)]\tLoss: 18.460894\n","Train Epoch: 69 [22368/33609 (67%)]\tLoss: 19.218830\n","Train Epoch: 69 [25568/33609 (76%)]\tLoss: 18.869482\n","Train Epoch: 69 [28768/33609 (86%)]\tLoss: 22.302143\n","Train Epoch: 69 [31968/33609 (95%)]\tLoss: 18.010530\n","====> Epoch: 69 Average loss: 19.1473\n","Train Epoch: 70 [3168/33609 (9%)]\tLoss: 18.092863\n","Train Epoch: 70 [6368/33609 (19%)]\tLoss: 19.912455\n","Train Epoch: 70 [9568/33609 (28%)]\tLoss: 20.311338\n","Train Epoch: 70 [12768/33609 (38%)]\tLoss: 19.061321\n","Train Epoch: 70 [15968/33609 (47%)]\tLoss: 22.287163\n","Train Epoch: 70 [19168/33609 (57%)]\tLoss: 17.648884\n","Train Epoch: 70 [22368/33609 (67%)]\tLoss: 20.874401\n","Train Epoch: 70 [25568/33609 (76%)]\tLoss: 20.410007\n","Train Epoch: 70 [28768/33609 (86%)]\tLoss: 16.533747\n","Train Epoch: 70 [31968/33609 (95%)]\tLoss: 20.653332\n","====> Epoch: 70 Average loss: 18.6040\n","Train Epoch: 71 [3168/33609 (9%)]\tLoss: 20.330387\n","Train Epoch: 71 [6368/33609 (19%)]\tLoss: 19.134775\n","Train Epoch: 71 [9568/33609 (28%)]\tLoss: 18.428404\n","Train Epoch: 71 [12768/33609 (38%)]\tLoss: 15.166805\n","Train Epoch: 71 [15968/33609 (47%)]\tLoss: 15.066606\n","Train Epoch: 71 [19168/33609 (57%)]\tLoss: 20.587444\n","Train Epoch: 71 [22368/33609 (67%)]\tLoss: 18.046007\n","Train Epoch: 71 [25568/33609 (76%)]\tLoss: 18.015636\n","Train Epoch: 71 [28768/33609 (86%)]\tLoss: 17.239065\n","Train Epoch: 71 [31968/33609 (95%)]\tLoss: 20.170218\n","====> Epoch: 71 Average loss: 18.2883\n","Train Epoch: 72 [3168/33609 (9%)]\tLoss: 19.402618\n","Train Epoch: 72 [6368/33609 (19%)]\tLoss: 15.290751\n","Train Epoch: 72 [9568/33609 (28%)]\tLoss: 17.295488\n","Train Epoch: 72 [12768/33609 (38%)]\tLoss: 17.762690\n","Train Epoch: 72 [15968/33609 (47%)]\tLoss: 19.581596\n","Train Epoch: 72 [19168/33609 (57%)]\tLoss: 18.003845\n","Train Epoch: 72 [22368/33609 (67%)]\tLoss: 18.791851\n","Train Epoch: 72 [25568/33609 (76%)]\tLoss: 15.256920\n","Train Epoch: 72 [28768/33609 (86%)]\tLoss: 19.849051\n","Train Epoch: 72 [31968/33609 (95%)]\tLoss: 16.063553\n","====> Epoch: 72 Average loss: 18.1318\n","Train Epoch: 73 [3168/33609 (9%)]\tLoss: 17.053934\n","Train Epoch: 73 [6368/33609 (19%)]\tLoss: 17.603695\n","Train Epoch: 73 [9568/33609 (28%)]\tLoss: 18.120888\n","Train Epoch: 73 [12768/33609 (38%)]\tLoss: 16.589075\n","Train Epoch: 73 [15968/33609 (47%)]\tLoss: 17.675432\n","Train Epoch: 73 [19168/33609 (57%)]\tLoss: 18.821358\n","Train Epoch: 73 [22368/33609 (67%)]\tLoss: 16.737783\n","Train Epoch: 73 [25568/33609 (76%)]\tLoss: 17.796444\n","Train Epoch: 73 [28768/33609 (86%)]\tLoss: 18.293350\n","Train Epoch: 73 [31968/33609 (95%)]\tLoss: 15.731960\n","====> Epoch: 73 Average loss: 18.5640\n","Train Epoch: 74 [3168/33609 (9%)]\tLoss: 17.834984\n","Train Epoch: 74 [6368/33609 (19%)]\tLoss: 18.501305\n","Train Epoch: 74 [9568/33609 (28%)]\tLoss: 16.696077\n","Train Epoch: 74 [12768/33609 (38%)]\tLoss: 18.469923\n","Train Epoch: 74 [15968/33609 (47%)]\tLoss: 19.630833\n","Train Epoch: 74 [19168/33609 (57%)]\tLoss: 18.899746\n","Train Epoch: 74 [22368/33609 (67%)]\tLoss: 15.921582\n","Train Epoch: 74 [25568/33609 (76%)]\tLoss: 15.792506\n","Train Epoch: 74 [28768/33609 (86%)]\tLoss: 18.026169\n","Train Epoch: 74 [31968/33609 (95%)]\tLoss: 17.651257\n","====> Epoch: 74 Average loss: 18.1253\n","Train Epoch: 75 [3168/33609 (9%)]\tLoss: 19.987726\n","Train Epoch: 75 [6368/33609 (19%)]\tLoss: 16.456264\n","Train Epoch: 75 [9568/33609 (28%)]\tLoss: 16.534563\n","Train Epoch: 75 [12768/33609 (38%)]\tLoss: 15.790557\n","Train Epoch: 75 [15968/33609 (47%)]\tLoss: 19.516529\n","Train Epoch: 75 [19168/33609 (57%)]\tLoss: 18.767458\n","Train Epoch: 75 [22368/33609 (67%)]\tLoss: 18.246685\n","Train Epoch: 75 [25568/33609 (76%)]\tLoss: 17.585751\n","Train Epoch: 75 [28768/33609 (86%)]\tLoss: 18.917683\n","Train Epoch: 75 [31968/33609 (95%)]\tLoss: 17.932642\n","====> Epoch: 75 Average loss: 18.0239\n","Train Epoch: 76 [3168/33609 (9%)]\tLoss: 15.944002\n","Train Epoch: 76 [6368/33609 (19%)]\tLoss: 22.244553\n","Train Epoch: 76 [9568/33609 (28%)]\tLoss: 16.675314\n","Train Epoch: 76 [12768/33609 (38%)]\tLoss: 18.141949\n","Train Epoch: 76 [15968/33609 (47%)]\tLoss: 19.835968\n","Train Epoch: 76 [19168/33609 (57%)]\tLoss: 19.601994\n","Train Epoch: 76 [22368/33609 (67%)]\tLoss: 16.945013\n","Train Epoch: 76 [25568/33609 (76%)]\tLoss: 17.842512\n","Train Epoch: 76 [28768/33609 (86%)]\tLoss: 17.040470\n","Train Epoch: 76 [31968/33609 (95%)]\tLoss: 17.681618\n","====> Epoch: 76 Average loss: 18.0000\n","Train Epoch: 77 [3168/33609 (9%)]\tLoss: 20.009953\n","Train Epoch: 77 [6368/33609 (19%)]\tLoss: 16.444841\n","Train Epoch: 77 [9568/33609 (28%)]\tLoss: 17.820354\n","Train Epoch: 77 [12768/33609 (38%)]\tLoss: 18.886478\n","Train Epoch: 77 [15968/33609 (47%)]\tLoss: 19.025616\n","Train Epoch: 77 [19168/33609 (57%)]\tLoss: 17.001474\n","Train Epoch: 77 [22368/33609 (67%)]\tLoss: 17.747358\n","Train Epoch: 77 [25568/33609 (76%)]\tLoss: 17.174889\n","Train Epoch: 77 [28768/33609 (86%)]\tLoss: 17.730091\n","Train Epoch: 77 [31968/33609 (95%)]\tLoss: 17.314184\n","====> Epoch: 77 Average loss: 17.8854\n","Train Epoch: 78 [3168/33609 (9%)]\tLoss: 21.092335\n","Train Epoch: 78 [6368/33609 (19%)]\tLoss: 15.648987\n","Train Epoch: 78 [9568/33609 (28%)]\tLoss: 17.709070\n","Train Epoch: 78 [12768/33609 (38%)]\tLoss: 20.851437\n","Train Epoch: 78 [15968/33609 (47%)]\tLoss: 14.462936\n","Train Epoch: 78 [19168/33609 (57%)]\tLoss: 17.869551\n","Train Epoch: 78 [22368/33609 (67%)]\tLoss: 16.275478\n","Train Epoch: 78 [25568/33609 (76%)]\tLoss: 15.624267\n","Train Epoch: 78 [28768/33609 (86%)]\tLoss: 18.815441\n","Train Epoch: 78 [31968/33609 (95%)]\tLoss: 17.156647\n","====> Epoch: 78 Average loss: 17.8590\n","Train Epoch: 79 [3168/33609 (9%)]\tLoss: 18.390577\n","Train Epoch: 79 [6368/33609 (19%)]\tLoss: 20.536524\n","Train Epoch: 79 [9568/33609 (28%)]\tLoss: 17.488874\n","Train Epoch: 79 [12768/33609 (38%)]\tLoss: 17.137436\n","Train Epoch: 79 [15968/33609 (47%)]\tLoss: 16.899361\n","Train Epoch: 79 [19168/33609 (57%)]\tLoss: 19.104448\n","Train Epoch: 79 [22368/33609 (67%)]\tLoss: 15.608965\n","Train Epoch: 79 [25568/33609 (76%)]\tLoss: 17.714859\n","Train Epoch: 79 [28768/33609 (86%)]\tLoss: 16.693390\n","Train Epoch: 79 [31968/33609 (95%)]\tLoss: 17.551439\n","====> Epoch: 79 Average loss: 17.8015\n","Train Epoch: 80 [3168/33609 (9%)]\tLoss: 17.558931\n","Train Epoch: 80 [6368/33609 (19%)]\tLoss: 18.528839\n","Train Epoch: 80 [9568/33609 (28%)]\tLoss: 17.368603\n","Train Epoch: 80 [12768/33609 (38%)]\tLoss: 18.598269\n","Train Epoch: 80 [15968/33609 (47%)]\tLoss: 18.192120\n","Train Epoch: 80 [19168/33609 (57%)]\tLoss: 20.029629\n","Train Epoch: 80 [22368/33609 (67%)]\tLoss: 17.127428\n","Train Epoch: 80 [25568/33609 (76%)]\tLoss: 18.658253\n","Train Epoch: 80 [28768/33609 (86%)]\tLoss: 16.320183\n","Train Epoch: 80 [31968/33609 (95%)]\tLoss: 21.576181\n","====> Epoch: 80 Average loss: 17.8483\n","Train Epoch: 81 [3168/33609 (9%)]\tLoss: 16.611326\n","Train Epoch: 81 [6368/33609 (19%)]\tLoss: 18.851406\n","Train Epoch: 81 [9568/33609 (28%)]\tLoss: 16.017683\n","Train Epoch: 81 [12768/33609 (38%)]\tLoss: 15.830475\n","Train Epoch: 81 [15968/33609 (47%)]\tLoss: 17.007221\n","Train Epoch: 81 [19168/33609 (57%)]\tLoss: 17.107361\n","Train Epoch: 81 [22368/33609 (67%)]\tLoss: 18.294081\n","Train Epoch: 81 [25568/33609 (76%)]\tLoss: 21.473816\n","Train Epoch: 81 [28768/33609 (86%)]\tLoss: 17.863365\n","Train Epoch: 81 [31968/33609 (95%)]\tLoss: 16.979881\n","====> Epoch: 81 Average loss: 17.8255\n","Train Epoch: 82 [3168/33609 (9%)]\tLoss: 15.818361\n","Train Epoch: 82 [6368/33609 (19%)]\tLoss: 17.276678\n","Train Epoch: 82 [9568/33609 (28%)]\tLoss: 17.365973\n","Train Epoch: 82 [12768/33609 (38%)]\tLoss: 18.286041\n","Train Epoch: 82 [15968/33609 (47%)]\tLoss: 18.745871\n","Train Epoch: 82 [19168/33609 (57%)]\tLoss: 17.205677\n","Train Epoch: 82 [22368/33609 (67%)]\tLoss: 17.154610\n","Train Epoch: 82 [25568/33609 (76%)]\tLoss: 18.560671\n","Train Epoch: 82 [28768/33609 (86%)]\tLoss: 18.036121\n","Train Epoch: 82 [31968/33609 (95%)]\tLoss: 18.090500\n","====> Epoch: 82 Average loss: 17.7514\n","Train Epoch: 83 [3168/33609 (9%)]\tLoss: 15.275620\n","Train Epoch: 83 [6368/33609 (19%)]\tLoss: 15.854864\n","Train Epoch: 83 [9568/33609 (28%)]\tLoss: 18.058876\n","Train Epoch: 83 [12768/33609 (38%)]\tLoss: 17.079865\n","Train Epoch: 83 [15968/33609 (47%)]\tLoss: 21.455572\n","Train Epoch: 83 [19168/33609 (57%)]\tLoss: 18.377558\n","Train Epoch: 83 [22368/33609 (67%)]\tLoss: 17.961740\n","Train Epoch: 83 [25568/33609 (76%)]\tLoss: 18.639826\n","Train Epoch: 83 [28768/33609 (86%)]\tLoss: 18.512018\n","Train Epoch: 83 [31968/33609 (95%)]\tLoss: 17.436815\n","====> Epoch: 83 Average loss: 17.7287\n","Train Epoch: 84 [3168/33609 (9%)]\tLoss: 19.453320\n","Train Epoch: 84 [6368/33609 (19%)]\tLoss: 17.838909\n","Train Epoch: 84 [9568/33609 (28%)]\tLoss: 18.389433\n","Train Epoch: 84 [12768/33609 (38%)]\tLoss: 20.684780\n","Train Epoch: 84 [15968/33609 (47%)]\tLoss: 17.871099\n","Train Epoch: 84 [19168/33609 (57%)]\tLoss: 17.668001\n","Train Epoch: 84 [22368/33609 (67%)]\tLoss: 19.835421\n","Train Epoch: 84 [25568/33609 (76%)]\tLoss: 19.706814\n","Train Epoch: 84 [28768/33609 (86%)]\tLoss: 16.662661\n","Train Epoch: 84 [31968/33609 (95%)]\tLoss: 19.186050\n","====> Epoch: 84 Average loss: 17.7342\n","Train Epoch: 85 [3168/33609 (9%)]\tLoss: 16.030777\n","Train Epoch: 85 [6368/33609 (19%)]\tLoss: 19.374084\n","Train Epoch: 85 [9568/33609 (28%)]\tLoss: 13.656720\n","Train Epoch: 85 [12768/33609 (38%)]\tLoss: 19.658319\n","Train Epoch: 85 [15968/33609 (47%)]\tLoss: 19.325617\n","Train Epoch: 85 [19168/33609 (57%)]\tLoss: 18.492624\n","Train Epoch: 85 [22368/33609 (67%)]\tLoss: 18.303221\n","Train Epoch: 85 [25568/33609 (76%)]\tLoss: 17.462126\n","Train Epoch: 85 [28768/33609 (86%)]\tLoss: 17.477703\n","Train Epoch: 85 [31968/33609 (95%)]\tLoss: 17.502432\n","====> Epoch: 85 Average loss: 17.7273\n","Train Epoch: 86 [3168/33609 (9%)]\tLoss: 19.043016\n","Train Epoch: 86 [6368/33609 (19%)]\tLoss: 14.923751\n","Train Epoch: 86 [9568/33609 (28%)]\tLoss: 16.691271\n","Train Epoch: 86 [12768/33609 (38%)]\tLoss: 17.511948\n","Train Epoch: 86 [15968/33609 (47%)]\tLoss: 19.647907\n","Train Epoch: 86 [19168/33609 (57%)]\tLoss: 17.964991\n","Train Epoch: 86 [22368/33609 (67%)]\tLoss: 15.401589\n","Train Epoch: 86 [25568/33609 (76%)]\tLoss: 14.769844\n","Train Epoch: 86 [28768/33609 (86%)]\tLoss: 15.831452\n","Train Epoch: 86 [31968/33609 (95%)]\tLoss: 17.299883\n","====> Epoch: 86 Average loss: 17.7038\n","Train Epoch: 87 [3168/33609 (9%)]\tLoss: 17.823742\n","Train Epoch: 87 [6368/33609 (19%)]\tLoss: 15.831987\n","Train Epoch: 87 [9568/33609 (28%)]\tLoss: 20.411757\n","Train Epoch: 87 [12768/33609 (38%)]\tLoss: 17.130152\n","Train Epoch: 87 [15968/33609 (47%)]\tLoss: 17.267056\n","Train Epoch: 87 [19168/33609 (57%)]\tLoss: 17.860781\n","Train Epoch: 87 [22368/33609 (67%)]\tLoss: 17.519686\n","Train Epoch: 87 [25568/33609 (76%)]\tLoss: 19.858921\n","Train Epoch: 87 [28768/33609 (86%)]\tLoss: 19.422752\n","Train Epoch: 87 [31968/33609 (95%)]\tLoss: 19.004145\n","====> Epoch: 87 Average loss: 17.6963\n","Train Epoch: 88 [3168/33609 (9%)]\tLoss: 20.111393\n","Train Epoch: 88 [6368/33609 (19%)]\tLoss: 19.025503\n","Train Epoch: 88 [9568/33609 (28%)]\tLoss: 16.350109\n","Train Epoch: 88 [12768/33609 (38%)]\tLoss: 19.188068\n","Train Epoch: 88 [15968/33609 (47%)]\tLoss: 18.582731\n","Train Epoch: 88 [19168/33609 (57%)]\tLoss: 16.680805\n","Train Epoch: 88 [22368/33609 (67%)]\tLoss: 17.968796\n","Train Epoch: 88 [25568/33609 (76%)]\tLoss: 20.134624\n","Train Epoch: 88 [28768/33609 (86%)]\tLoss: 19.320776\n","Train Epoch: 88 [31968/33609 (95%)]\tLoss: 20.538151\n","====> Epoch: 88 Average loss: 17.7550\n","Train Epoch: 89 [3168/33609 (9%)]\tLoss: 18.887659\n","Train Epoch: 89 [6368/33609 (19%)]\tLoss: 17.502180\n","Train Epoch: 89 [9568/33609 (28%)]\tLoss: 15.418017\n","Train Epoch: 89 [12768/33609 (38%)]\tLoss: 17.155273\n","Train Epoch: 89 [15968/33609 (47%)]\tLoss: 17.824760\n","Train Epoch: 89 [19168/33609 (57%)]\tLoss: 16.982882\n","Train Epoch: 89 [22368/33609 (67%)]\tLoss: 18.525471\n","Train Epoch: 89 [25568/33609 (76%)]\tLoss: 17.163754\n","Train Epoch: 89 [28768/33609 (86%)]\tLoss: 20.100718\n","Train Epoch: 89 [31968/33609 (95%)]\tLoss: 19.473558\n","====> Epoch: 89 Average loss: 17.7200\n","Train Epoch: 90 [3168/33609 (9%)]\tLoss: 13.110857\n","Train Epoch: 90 [6368/33609 (19%)]\tLoss: 18.591110\n","Train Epoch: 90 [9568/33609 (28%)]\tLoss: 20.081148\n","Train Epoch: 90 [12768/33609 (38%)]\tLoss: 19.986227\n","Train Epoch: 90 [15968/33609 (47%)]\tLoss: 17.328588\n","Train Epoch: 90 [19168/33609 (57%)]\tLoss: 21.298597\n","Train Epoch: 90 [22368/33609 (67%)]\tLoss: 22.111547\n","Train Epoch: 90 [25568/33609 (76%)]\tLoss: 18.476357\n","Train Epoch: 90 [28768/33609 (86%)]\tLoss: 18.155457\n","Train Epoch: 90 [31968/33609 (95%)]\tLoss: 17.533213\n","====> Epoch: 90 Average loss: 17.6761\n","Train Epoch: 91 [3168/33609 (9%)]\tLoss: 17.684469\n","Train Epoch: 91 [6368/33609 (19%)]\tLoss: 15.404318\n","Train Epoch: 91 [9568/33609 (28%)]\tLoss: 12.283536\n","Train Epoch: 91 [12768/33609 (38%)]\tLoss: 17.994856\n","Train Epoch: 91 [15968/33609 (47%)]\tLoss: 17.276773\n","Train Epoch: 91 [19168/33609 (57%)]\tLoss: 17.526947\n","Train Epoch: 91 [22368/33609 (67%)]\tLoss: 20.124454\n","Train Epoch: 91 [25568/33609 (76%)]\tLoss: 15.410422\n","Train Epoch: 91 [28768/33609 (86%)]\tLoss: 16.958513\n","Train Epoch: 91 [31968/33609 (95%)]\tLoss: 16.789635\n","====> Epoch: 91 Average loss: 17.6846\n","Train Epoch: 92 [3168/33609 (9%)]\tLoss: 16.358017\n","Train Epoch: 92 [6368/33609 (19%)]\tLoss: 18.304468\n","Train Epoch: 92 [9568/33609 (28%)]\tLoss: 14.513338\n","Train Epoch: 92 [12768/33609 (38%)]\tLoss: 16.343872\n","Train Epoch: 92 [15968/33609 (47%)]\tLoss: 16.426960\n","Train Epoch: 92 [19168/33609 (57%)]\tLoss: 17.598356\n","Train Epoch: 92 [22368/33609 (67%)]\tLoss: 19.766027\n","Train Epoch: 92 [25568/33609 (76%)]\tLoss: 18.185236\n","Train Epoch: 92 [28768/33609 (86%)]\tLoss: 14.240594\n","Train Epoch: 92 [31968/33609 (95%)]\tLoss: 16.397011\n","====> Epoch: 92 Average loss: 17.6834\n","Train Epoch: 93 [3168/33609 (9%)]\tLoss: 18.479645\n","Train Epoch: 93 [6368/33609 (19%)]\tLoss: 19.112930\n","Train Epoch: 93 [9568/33609 (28%)]\tLoss: 17.528196\n","Train Epoch: 93 [12768/33609 (38%)]\tLoss: 19.923664\n","Train Epoch: 93 [15968/33609 (47%)]\tLoss: 17.286259\n","Train Epoch: 93 [19168/33609 (57%)]\tLoss: 17.892675\n","Train Epoch: 93 [22368/33609 (67%)]\tLoss: 16.274700\n","Train Epoch: 93 [25568/33609 (76%)]\tLoss: 15.992360\n","Train Epoch: 93 [28768/33609 (86%)]\tLoss: 18.495464\n","Train Epoch: 93 [31968/33609 (95%)]\tLoss: 19.480787\n","====> Epoch: 93 Average loss: 17.6831\n","Train Epoch: 94 [3168/33609 (9%)]\tLoss: 16.949434\n","Train Epoch: 94 [6368/33609 (19%)]\tLoss: 17.450537\n","Train Epoch: 94 [9568/33609 (28%)]\tLoss: 16.403860\n","Train Epoch: 94 [12768/33609 (38%)]\tLoss: 17.226425\n","Train Epoch: 94 [15968/33609 (47%)]\tLoss: 14.742960\n","Train Epoch: 94 [19168/33609 (57%)]\tLoss: 16.927015\n","Train Epoch: 94 [22368/33609 (67%)]\tLoss: 15.937536\n","Train Epoch: 94 [25568/33609 (76%)]\tLoss: 15.306938\n","Train Epoch: 94 [28768/33609 (86%)]\tLoss: 18.043789\n","Train Epoch: 94 [31968/33609 (95%)]\tLoss: 18.334572\n","====> Epoch: 94 Average loss: 17.6587\n","Train Epoch: 95 [3168/33609 (9%)]\tLoss: 20.341290\n","Train Epoch: 95 [6368/33609 (19%)]\tLoss: 17.241693\n","Train Epoch: 95 [9568/33609 (28%)]\tLoss: 17.658867\n","Train Epoch: 95 [12768/33609 (38%)]\tLoss: 17.298279\n","Train Epoch: 95 [15968/33609 (47%)]\tLoss: 19.001244\n","Train Epoch: 95 [19168/33609 (57%)]\tLoss: 16.055325\n","Train Epoch: 95 [22368/33609 (67%)]\tLoss: 18.423428\n","Train Epoch: 95 [25568/33609 (76%)]\tLoss: 16.098963\n","Train Epoch: 95 [28768/33609 (86%)]\tLoss: 15.127768\n","Train Epoch: 95 [31968/33609 (95%)]\tLoss: 14.839644\n","====> Epoch: 95 Average loss: 17.6573\n","Train Epoch: 96 [3168/33609 (9%)]\tLoss: 17.968473\n","Train Epoch: 96 [6368/33609 (19%)]\tLoss: 15.174477\n","Train Epoch: 96 [9568/33609 (28%)]\tLoss: 16.084196\n","Train Epoch: 96 [12768/33609 (38%)]\tLoss: 16.450260\n","Train Epoch: 96 [15968/33609 (47%)]\tLoss: 16.763124\n","Train Epoch: 96 [19168/33609 (57%)]\tLoss: 17.891365\n","Train Epoch: 96 [22368/33609 (67%)]\tLoss: 15.060318\n","Train Epoch: 96 [25568/33609 (76%)]\tLoss: 17.694031\n","Train Epoch: 96 [28768/33609 (86%)]\tLoss: 18.747831\n","Train Epoch: 96 [31968/33609 (95%)]\tLoss: 16.294891\n","====> Epoch: 96 Average loss: 17.6871\n","Train Epoch: 97 [3168/33609 (9%)]\tLoss: 16.879042\n","Train Epoch: 97 [6368/33609 (19%)]\tLoss: 17.393669\n","Train Epoch: 97 [9568/33609 (28%)]\tLoss: 14.819521\n","Train Epoch: 97 [12768/33609 (38%)]\tLoss: 18.489323\n","Train Epoch: 97 [15968/33609 (47%)]\tLoss: 18.367924\n","Train Epoch: 97 [19168/33609 (57%)]\tLoss: 16.016542\n","Train Epoch: 97 [22368/33609 (67%)]\tLoss: 16.079163\n","Train Epoch: 97 [25568/33609 (76%)]\tLoss: 19.667931\n","Train Epoch: 97 [28768/33609 (86%)]\tLoss: 16.278553\n","Train Epoch: 97 [31968/33609 (95%)]\tLoss: 16.243975\n","====> Epoch: 97 Average loss: 17.7057\n","Train Epoch: 98 [3168/33609 (9%)]\tLoss: 16.515938\n","Train Epoch: 98 [6368/33609 (19%)]\tLoss: 17.843328\n","Train Epoch: 98 [9568/33609 (28%)]\tLoss: 16.444244\n","Train Epoch: 98 [12768/33609 (38%)]\tLoss: 16.725971\n","Train Epoch: 98 [15968/33609 (47%)]\tLoss: 17.883926\n","Train Epoch: 98 [19168/33609 (57%)]\tLoss: 14.479587\n","Train Epoch: 98 [22368/33609 (67%)]\tLoss: 14.846930\n","Train Epoch: 98 [25568/33609 (76%)]\tLoss: 18.098888\n","Train Epoch: 98 [28768/33609 (86%)]\tLoss: 18.098923\n","Train Epoch: 98 [31968/33609 (95%)]\tLoss: 18.605038\n","====> Epoch: 98 Average loss: 17.6641\n","Train Epoch: 99 [3168/33609 (9%)]\tLoss: 17.413940\n","Train Epoch: 99 [6368/33609 (19%)]\tLoss: 19.224413\n","Train Epoch: 99 [9568/33609 (28%)]\tLoss: 14.766553\n","Train Epoch: 99 [12768/33609 (38%)]\tLoss: 16.132236\n","Train Epoch: 99 [15968/33609 (47%)]\tLoss: 18.534382\n","Train Epoch: 99 [19168/33609 (57%)]\tLoss: 15.950680\n","Train Epoch: 99 [22368/33609 (67%)]\tLoss: 16.630085\n","Train Epoch: 99 [25568/33609 (76%)]\tLoss: 17.046543\n","Train Epoch: 99 [28768/33609 (86%)]\tLoss: 17.091677\n","Train Epoch: 99 [31968/33609 (95%)]\tLoss: 15.829758\n","====> Epoch: 99 Average loss: 17.6668\n","Train Epoch: 100 [3168/33609 (9%)]\tLoss: 16.550144\n","Train Epoch: 100 [6368/33609 (19%)]\tLoss: 17.244473\n","Train Epoch: 100 [9568/33609 (28%)]\tLoss: 19.408239\n","Train Epoch: 100 [12768/33609 (38%)]\tLoss: 14.638556\n","Train Epoch: 100 [15968/33609 (47%)]\tLoss: 17.685623\n","Train Epoch: 100 [19168/33609 (57%)]\tLoss: 19.407887\n","Train Epoch: 100 [22368/33609 (67%)]\tLoss: 20.707279\n","Train Epoch: 100 [25568/33609 (76%)]\tLoss: 16.987644\n","Train Epoch: 100 [28768/33609 (86%)]\tLoss: 17.470158\n","Train Epoch: 100 [31968/33609 (95%)]\tLoss: 15.048616\n","====> Epoch: 100 Average loss: 17.6791\n","Train Epoch: 101 [3168/33609 (9%)]\tLoss: 15.227848\n","Train Epoch: 101 [6368/33609 (19%)]\tLoss: 16.568665\n","Train Epoch: 101 [9568/33609 (28%)]\tLoss: 17.264509\n","Train Epoch: 101 [12768/33609 (38%)]\tLoss: 13.829341\n","Train Epoch: 101 [15968/33609 (47%)]\tLoss: 15.680433\n","Train Epoch: 101 [19168/33609 (57%)]\tLoss: 18.634758\n","Train Epoch: 101 [22368/33609 (67%)]\tLoss: 19.534000\n","Train Epoch: 101 [25568/33609 (76%)]\tLoss: 15.854526\n","Train Epoch: 101 [28768/33609 (86%)]\tLoss: 13.280620\n","Train Epoch: 101 [31968/33609 (95%)]\tLoss: 19.029078\n","====> Epoch: 101 Average loss: 17.6829\n","Train Epoch: 102 [3168/33609 (9%)]\tLoss: 15.711309\n","Train Epoch: 102 [6368/33609 (19%)]\tLoss: 17.750662\n","Train Epoch: 102 [9568/33609 (28%)]\tLoss: 16.343843\n","Train Epoch: 102 [12768/33609 (38%)]\tLoss: 17.004379\n","Train Epoch: 102 [15968/33609 (47%)]\tLoss: 16.854160\n","Train Epoch: 102 [19168/33609 (57%)]\tLoss: 15.213062\n","Train Epoch: 102 [22368/33609 (67%)]\tLoss: 16.877480\n","Train Epoch: 102 [25568/33609 (76%)]\tLoss: 16.898798\n","Train Epoch: 102 [28768/33609 (86%)]\tLoss: 17.527384\n","Train Epoch: 102 [31968/33609 (95%)]\tLoss: 22.925034\n","====> Epoch: 102 Average loss: 17.6532\n","Train Epoch: 103 [3168/33609 (9%)]\tLoss: 15.998838\n","Train Epoch: 103 [6368/33609 (19%)]\tLoss: 16.071840\n","Train Epoch: 103 [9568/33609 (28%)]\tLoss: 18.523806\n","Train Epoch: 103 [12768/33609 (38%)]\tLoss: 16.601337\n","Train Epoch: 103 [15968/33609 (47%)]\tLoss: 18.443108\n","Train Epoch: 103 [19168/33609 (57%)]\tLoss: 18.104950\n","Train Epoch: 103 [22368/33609 (67%)]\tLoss: 16.877760\n","Train Epoch: 103 [25568/33609 (76%)]\tLoss: 18.430813\n","Train Epoch: 103 [28768/33609 (86%)]\tLoss: 17.516174\n","Train Epoch: 103 [31968/33609 (95%)]\tLoss: 19.321491\n","====> Epoch: 103 Average loss: 17.6453\n","Train Epoch: 104 [3168/33609 (9%)]\tLoss: 18.032671\n","Train Epoch: 104 [6368/33609 (19%)]\tLoss: 19.106056\n","Train Epoch: 104 [9568/33609 (28%)]\tLoss: 15.866877\n","Train Epoch: 104 [12768/33609 (38%)]\tLoss: 13.522219\n","Train Epoch: 104 [15968/33609 (47%)]\tLoss: 18.587803\n","Train Epoch: 104 [19168/33609 (57%)]\tLoss: 18.710575\n","Train Epoch: 104 [22368/33609 (67%)]\tLoss: 17.986900\n","Train Epoch: 104 [25568/33609 (76%)]\tLoss: 15.689124\n","Train Epoch: 104 [28768/33609 (86%)]\tLoss: 14.960738\n","Train Epoch: 104 [31968/33609 (95%)]\tLoss: 18.260651\n","====> Epoch: 104 Average loss: 17.6696\n","Train Epoch: 105 [3168/33609 (9%)]\tLoss: 16.742760\n","Train Epoch: 105 [6368/33609 (19%)]\tLoss: 16.496546\n","Train Epoch: 105 [9568/33609 (28%)]\tLoss: 16.456356\n","Train Epoch: 105 [12768/33609 (38%)]\tLoss: 17.607502\n","Train Epoch: 105 [15968/33609 (47%)]\tLoss: 15.243558\n","Train Epoch: 105 [19168/33609 (57%)]\tLoss: 17.554893\n","Train Epoch: 105 [22368/33609 (67%)]\tLoss: 18.926947\n","Train Epoch: 105 [25568/33609 (76%)]\tLoss: 17.387871\n","Train Epoch: 105 [28768/33609 (86%)]\tLoss: 17.196522\n","Train Epoch: 105 [31968/33609 (95%)]\tLoss: 20.975965\n","====> Epoch: 105 Average loss: 17.6657\n","Train Epoch: 106 [3168/33609 (9%)]\tLoss: 18.413082\n","Train Epoch: 106 [6368/33609 (19%)]\tLoss: 17.044527\n","Train Epoch: 106 [9568/33609 (28%)]\tLoss: 14.804251\n","Train Epoch: 106 [12768/33609 (38%)]\tLoss: 18.193651\n","Train Epoch: 106 [15968/33609 (47%)]\tLoss: 19.892450\n","Train Epoch: 106 [19168/33609 (57%)]\tLoss: 17.621346\n","Train Epoch: 106 [22368/33609 (67%)]\tLoss: 17.864908\n","Train Epoch: 106 [25568/33609 (76%)]\tLoss: 17.111401\n","Train Epoch: 106 [28768/33609 (86%)]\tLoss: 17.969757\n","Train Epoch: 106 [31968/33609 (95%)]\tLoss: 17.379435\n","====> Epoch: 106 Average loss: 17.6420\n","Train Epoch: 107 [3168/33609 (9%)]\tLoss: 16.553572\n","Train Epoch: 107 [6368/33609 (19%)]\tLoss: 16.109062\n","Train Epoch: 107 [9568/33609 (28%)]\tLoss: 18.722408\n","Train Epoch: 107 [12768/33609 (38%)]\tLoss: 17.467901\n","Train Epoch: 107 [15968/33609 (47%)]\tLoss: 16.879107\n","Train Epoch: 107 [19168/33609 (57%)]\tLoss: 19.178328\n","Train Epoch: 107 [22368/33609 (67%)]\tLoss: 15.513285\n","Train Epoch: 107 [25568/33609 (76%)]\tLoss: 18.739014\n","Train Epoch: 107 [28768/33609 (86%)]\tLoss: 20.085049\n","Train Epoch: 107 [31968/33609 (95%)]\tLoss: 16.818769\n","====> Epoch: 107 Average loss: 17.7081\n","Train Epoch: 108 [3168/33609 (9%)]\tLoss: 18.118774\n","Train Epoch: 108 [6368/33609 (19%)]\tLoss: 15.821999\n","Train Epoch: 108 [9568/33609 (28%)]\tLoss: 18.845787\n","Train Epoch: 108 [12768/33609 (38%)]\tLoss: 20.243452\n","Train Epoch: 108 [15968/33609 (47%)]\tLoss: 20.415804\n","Train Epoch: 108 [19168/33609 (57%)]\tLoss: 16.399227\n","Train Epoch: 108 [22368/33609 (67%)]\tLoss: 16.165306\n","Train Epoch: 108 [25568/33609 (76%)]\tLoss: 19.807734\n","Train Epoch: 108 [28768/33609 (86%)]\tLoss: 19.016100\n","Train Epoch: 108 [31968/33609 (95%)]\tLoss: 15.716722\n","====> Epoch: 108 Average loss: 17.6832\n","Train Epoch: 109 [3168/33609 (9%)]\tLoss: 15.471653\n","Train Epoch: 109 [6368/33609 (19%)]\tLoss: 15.960379\n","Train Epoch: 109 [9568/33609 (28%)]\tLoss: 19.406595\n","Train Epoch: 109 [12768/33609 (38%)]\tLoss: 18.496397\n","Train Epoch: 109 [15968/33609 (47%)]\tLoss: 18.732101\n","Train Epoch: 109 [19168/33609 (57%)]\tLoss: 15.975189\n","Train Epoch: 109 [22368/33609 (67%)]\tLoss: 16.799952\n","Train Epoch: 109 [25568/33609 (76%)]\tLoss: 19.958483\n","Train Epoch: 109 [28768/33609 (86%)]\tLoss: 17.532053\n","Train Epoch: 109 [31968/33609 (95%)]\tLoss: 15.405033\n","====> Epoch: 109 Average loss: 17.6579\n","Train Epoch: 110 [3168/33609 (9%)]\tLoss: 14.432827\n","Train Epoch: 110 [6368/33609 (19%)]\tLoss: 18.167559\n","Train Epoch: 110 [9568/33609 (28%)]\tLoss: 15.452319\n","Train Epoch: 110 [12768/33609 (38%)]\tLoss: 17.215954\n","Train Epoch: 110 [15968/33609 (47%)]\tLoss: 17.812813\n","Train Epoch: 110 [19168/33609 (57%)]\tLoss: 18.043455\n","Train Epoch: 110 [22368/33609 (67%)]\tLoss: 15.528105\n","Train Epoch: 110 [25568/33609 (76%)]\tLoss: 18.723280\n","Train Epoch: 110 [28768/33609 (86%)]\tLoss: 18.501991\n","Train Epoch: 110 [31968/33609 (95%)]\tLoss: 18.619982\n","====> Epoch: 110 Average loss: 17.6430\n","Train Epoch: 111 [3168/33609 (9%)]\tLoss: 20.021095\n","Train Epoch: 111 [6368/33609 (19%)]\tLoss: 18.516768\n","Train Epoch: 111 [9568/33609 (28%)]\tLoss: 18.057796\n","Train Epoch: 111 [12768/33609 (38%)]\tLoss: 13.609459\n","Train Epoch: 111 [15968/33609 (47%)]\tLoss: 17.101007\n","Train Epoch: 111 [19168/33609 (57%)]\tLoss: 16.530991\n","Train Epoch: 111 [22368/33609 (67%)]\tLoss: 16.603436\n","Train Epoch: 111 [25568/33609 (76%)]\tLoss: 19.675669\n","Train Epoch: 111 [28768/33609 (86%)]\tLoss: 21.321280\n","Train Epoch: 111 [31968/33609 (95%)]\tLoss: 18.983307\n","====> Epoch: 111 Average loss: 17.6362\n","Train Epoch: 112 [3168/33609 (9%)]\tLoss: 17.991129\n","Train Epoch: 112 [6368/33609 (19%)]\tLoss: 18.525526\n","Train Epoch: 112 [9568/33609 (28%)]\tLoss: 17.092524\n","Train Epoch: 112 [12768/33609 (38%)]\tLoss: 17.448830\n","Train Epoch: 112 [15968/33609 (47%)]\tLoss: 12.753934\n","Train Epoch: 112 [19168/33609 (57%)]\tLoss: 21.510311\n","Train Epoch: 112 [22368/33609 (67%)]\tLoss: 17.780649\n","Train Epoch: 112 [25568/33609 (76%)]\tLoss: 17.293087\n","Train Epoch: 112 [28768/33609 (86%)]\tLoss: 17.784801\n","Train Epoch: 112 [31968/33609 (95%)]\tLoss: 20.857172\n","====> Epoch: 112 Average loss: 17.6530\n","Train Epoch: 113 [3168/33609 (9%)]\tLoss: 17.050716\n","Train Epoch: 113 [6368/33609 (19%)]\tLoss: 17.268875\n","Train Epoch: 113 [9568/33609 (28%)]\tLoss: 17.270596\n","Train Epoch: 113 [12768/33609 (38%)]\tLoss: 18.104820\n","Train Epoch: 113 [15968/33609 (47%)]\tLoss: 17.731226\n","Train Epoch: 113 [19168/33609 (57%)]\tLoss: 15.455478\n","Train Epoch: 113 [22368/33609 (67%)]\tLoss: 17.685890\n","Train Epoch: 113 [25568/33609 (76%)]\tLoss: 18.312204\n","Train Epoch: 113 [28768/33609 (86%)]\tLoss: 17.535210\n","Train Epoch: 113 [31968/33609 (95%)]\tLoss: 17.507120\n","====> Epoch: 113 Average loss: 17.6782\n","Train Epoch: 114 [3168/33609 (9%)]\tLoss: 18.140221\n","Train Epoch: 114 [6368/33609 (19%)]\tLoss: 18.337114\n","Train Epoch: 114 [9568/33609 (28%)]\tLoss: 19.392467\n","Train Epoch: 114 [12768/33609 (38%)]\tLoss: 18.716637\n","Train Epoch: 114 [15968/33609 (47%)]\tLoss: 17.588766\n","Train Epoch: 114 [19168/33609 (57%)]\tLoss: 16.224337\n","Train Epoch: 114 [22368/33609 (67%)]\tLoss: 20.125830\n","Train Epoch: 114 [25568/33609 (76%)]\tLoss: 18.948526\n","Train Epoch: 114 [28768/33609 (86%)]\tLoss: 14.829342\n","Train Epoch: 114 [31968/33609 (95%)]\tLoss: 16.670172\n","====> Epoch: 114 Average loss: 17.6346\n","Train Epoch: 115 [3168/33609 (9%)]\tLoss: 18.457705\n","Train Epoch: 115 [6368/33609 (19%)]\tLoss: 14.602116\n","Train Epoch: 115 [9568/33609 (28%)]\tLoss: 18.750053\n","Train Epoch: 115 [12768/33609 (38%)]\tLoss: 16.424372\n","Train Epoch: 115 [15968/33609 (47%)]\tLoss: 15.664975\n","Train Epoch: 115 [19168/33609 (57%)]\tLoss: 18.604027\n","Train Epoch: 115 [22368/33609 (67%)]\tLoss: 17.337656\n","Train Epoch: 115 [25568/33609 (76%)]\tLoss: 18.969954\n","Train Epoch: 115 [28768/33609 (86%)]\tLoss: 19.832325\n","Train Epoch: 115 [31968/33609 (95%)]\tLoss: 15.803596\n","====> Epoch: 115 Average loss: 17.6378\n","Train Epoch: 116 [3168/33609 (9%)]\tLoss: 19.534868\n","Train Epoch: 116 [6368/33609 (19%)]\tLoss: 19.112617\n","Train Epoch: 116 [9568/33609 (28%)]\tLoss: 18.865631\n","Train Epoch: 116 [12768/33609 (38%)]\tLoss: 20.197079\n","Train Epoch: 116 [15968/33609 (47%)]\tLoss: 18.131670\n","Train Epoch: 116 [19168/33609 (57%)]\tLoss: 16.268515\n","Train Epoch: 116 [22368/33609 (67%)]\tLoss: 22.310143\n","Train Epoch: 116 [25568/33609 (76%)]\tLoss: 16.137524\n","Train Epoch: 116 [28768/33609 (86%)]\tLoss: 18.086477\n","Train Epoch: 116 [31968/33609 (95%)]\tLoss: 19.023373\n","====> Epoch: 116 Average loss: 17.7557\n","Train Epoch: 117 [3168/33609 (9%)]\tLoss: 20.221848\n","Train Epoch: 117 [6368/33609 (19%)]\tLoss: 18.505272\n","Train Epoch: 117 [9568/33609 (28%)]\tLoss: 19.606606\n","Train Epoch: 117 [12768/33609 (38%)]\tLoss: 18.589018\n","Train Epoch: 117 [15968/33609 (47%)]\tLoss: 16.562269\n","Train Epoch: 117 [19168/33609 (57%)]\tLoss: 15.891280\n","Train Epoch: 117 [22368/33609 (67%)]\tLoss: 15.515681\n","Train Epoch: 117 [25568/33609 (76%)]\tLoss: 20.084496\n","Train Epoch: 117 [28768/33609 (86%)]\tLoss: 15.238750\n","Train Epoch: 117 [31968/33609 (95%)]\tLoss: 15.674967\n","====> Epoch: 117 Average loss: 17.7365\n","Train Epoch: 118 [3168/33609 (9%)]\tLoss: 14.621099\n","Train Epoch: 118 [6368/33609 (19%)]\tLoss: 18.972559\n","Train Epoch: 118 [9568/33609 (28%)]\tLoss: 16.266825\n","Train Epoch: 118 [12768/33609 (38%)]\tLoss: 16.202705\n","Train Epoch: 118 [15968/33609 (47%)]\tLoss: 18.724995\n","Train Epoch: 118 [19168/33609 (57%)]\tLoss: 21.894562\n","Train Epoch: 118 [22368/33609 (67%)]\tLoss: 16.834461\n","Train Epoch: 118 [25568/33609 (76%)]\tLoss: 17.453358\n","Train Epoch: 118 [28768/33609 (86%)]\tLoss: 20.090242\n","Train Epoch: 118 [31968/33609 (95%)]\tLoss: 18.637321\n","====> Epoch: 118 Average loss: 17.7179\n","Train Epoch: 119 [3168/33609 (9%)]\tLoss: 19.768929\n","Train Epoch: 119 [6368/33609 (19%)]\tLoss: 16.786768\n","Train Epoch: 119 [9568/33609 (28%)]\tLoss: 17.202595\n","Train Epoch: 119 [12768/33609 (38%)]\tLoss: 14.730820\n","Train Epoch: 119 [15968/33609 (47%)]\tLoss: 18.877337\n","Train Epoch: 119 [19168/33609 (57%)]\tLoss: 17.156261\n","Train Epoch: 119 [22368/33609 (67%)]\tLoss: 13.811506\n","Train Epoch: 119 [25568/33609 (76%)]\tLoss: 18.789913\n","Train Epoch: 119 [28768/33609 (86%)]\tLoss: 18.615965\n","Train Epoch: 119 [31968/33609 (95%)]\tLoss: 17.868053\n","====> Epoch: 119 Average loss: 17.7571\n","Train Epoch: 120 [3168/33609 (9%)]\tLoss: 17.272827\n","Train Epoch: 120 [6368/33609 (19%)]\tLoss: 22.280998\n","Train Epoch: 120 [9568/33609 (28%)]\tLoss: 16.314703\n","Train Epoch: 120 [12768/33609 (38%)]\tLoss: 16.346169\n","Train Epoch: 120 [15968/33609 (47%)]\tLoss: 17.853054\n","Train Epoch: 120 [19168/33609 (57%)]\tLoss: 17.802351\n","Train Epoch: 120 [22368/33609 (67%)]\tLoss: 17.880409\n","Train Epoch: 120 [25568/33609 (76%)]\tLoss: 14.639471\n","Train Epoch: 120 [28768/33609 (86%)]\tLoss: 17.294014\n","Train Epoch: 120 [31968/33609 (95%)]\tLoss: 16.374144\n","====> Epoch: 120 Average loss: 17.7116\n","Train Epoch: 121 [3168/33609 (9%)]\tLoss: 15.009812\n","Train Epoch: 121 [6368/33609 (19%)]\tLoss: 16.185261\n","Train Epoch: 121 [9568/33609 (28%)]\tLoss: 16.970036\n","Train Epoch: 121 [12768/33609 (38%)]\tLoss: 17.884720\n","Train Epoch: 121 [15968/33609 (47%)]\tLoss: 19.339855\n","Train Epoch: 121 [19168/33609 (57%)]\tLoss: 16.653461\n","Train Epoch: 121 [22368/33609 (67%)]\tLoss: 17.378880\n","Train Epoch: 121 [25568/33609 (76%)]\tLoss: 20.220779\n","Train Epoch: 121 [28768/33609 (86%)]\tLoss: 16.056604\n","Train Epoch: 121 [31968/33609 (95%)]\tLoss: 19.519213\n","====> Epoch: 121 Average loss: 17.6982\n","Train Epoch: 122 [3168/33609 (9%)]\tLoss: 20.402103\n","Train Epoch: 122 [6368/33609 (19%)]\tLoss: 17.374670\n","Train Epoch: 122 [9568/33609 (28%)]\tLoss: 18.707842\n","Train Epoch: 122 [12768/33609 (38%)]\tLoss: 17.698788\n","Train Epoch: 122 [15968/33609 (47%)]\tLoss: 16.988073\n","Train Epoch: 122 [19168/33609 (57%)]\tLoss: 16.355824\n","Train Epoch: 122 [22368/33609 (67%)]\tLoss: 19.166471\n","Train Epoch: 122 [25568/33609 (76%)]\tLoss: 18.183764\n","Train Epoch: 122 [28768/33609 (86%)]\tLoss: 19.239624\n","Train Epoch: 122 [31968/33609 (95%)]\tLoss: 20.600702\n","====> Epoch: 122 Average loss: 17.7052\n","Train Epoch: 123 [3168/33609 (9%)]\tLoss: 15.301218\n","Train Epoch: 123 [6368/33609 (19%)]\tLoss: 18.684078\n","Train Epoch: 123 [9568/33609 (28%)]\tLoss: 17.825520\n","Train Epoch: 123 [12768/33609 (38%)]\tLoss: 18.954971\n","Train Epoch: 123 [15968/33609 (47%)]\tLoss: 17.246920\n","Train Epoch: 123 [19168/33609 (57%)]\tLoss: 16.605608\n","Train Epoch: 123 [22368/33609 (67%)]\tLoss: 15.379267\n","Train Epoch: 123 [25568/33609 (76%)]\tLoss: 19.448040\n","Train Epoch: 123 [28768/33609 (86%)]\tLoss: 14.914640\n","Train Epoch: 123 [31968/33609 (95%)]\tLoss: 18.967436\n","====> Epoch: 123 Average loss: 17.6666\n","Train Epoch: 124 [3168/33609 (9%)]\tLoss: 18.308672\n","Train Epoch: 124 [6368/33609 (19%)]\tLoss: 18.499441\n","Train Epoch: 124 [9568/33609 (28%)]\tLoss: 16.718086\n","Train Epoch: 124 [12768/33609 (38%)]\tLoss: 18.861752\n","Train Epoch: 124 [15968/33609 (47%)]\tLoss: 16.220078\n","Train Epoch: 124 [19168/33609 (57%)]\tLoss: 16.270920\n","Train Epoch: 124 [22368/33609 (67%)]\tLoss: 19.315229\n","Train Epoch: 124 [25568/33609 (76%)]\tLoss: 16.500763\n","Train Epoch: 124 [28768/33609 (86%)]\tLoss: 16.636208\n","Train Epoch: 124 [31968/33609 (95%)]\tLoss: 19.659542\n","====> Epoch: 124 Average loss: 17.6880\n","Train Epoch: 125 [3168/33609 (9%)]\tLoss: 18.671318\n","Train Epoch: 125 [6368/33609 (19%)]\tLoss: 16.322367\n","Train Epoch: 125 [9568/33609 (28%)]\tLoss: 16.624981\n","Train Epoch: 125 [12768/33609 (38%)]\tLoss: 19.360233\n","Train Epoch: 125 [15968/33609 (47%)]\tLoss: 15.128335\n","Train Epoch: 125 [19168/33609 (57%)]\tLoss: 21.274958\n","Train Epoch: 125 [22368/33609 (67%)]\tLoss: 14.357384\n","Train Epoch: 125 [25568/33609 (76%)]\tLoss: 20.097452\n","Train Epoch: 125 [28768/33609 (86%)]\tLoss: 16.876554\n","Train Epoch: 125 [31968/33609 (95%)]\tLoss: 13.212016\n","====> Epoch: 125 Average loss: 17.6789\n","Train Epoch: 126 [3168/33609 (9%)]\tLoss: 17.423405\n","Train Epoch: 126 [6368/33609 (19%)]\tLoss: 16.953011\n","Train Epoch: 126 [9568/33609 (28%)]\tLoss: 13.148391\n","Train Epoch: 126 [12768/33609 (38%)]\tLoss: 16.448009\n","Train Epoch: 126 [15968/33609 (47%)]\tLoss: 17.056866\n","Train Epoch: 126 [19168/33609 (57%)]\tLoss: 19.394068\n","Train Epoch: 126 [22368/33609 (67%)]\tLoss: 15.358993\n","Train Epoch: 126 [25568/33609 (76%)]\tLoss: 18.198725\n","Train Epoch: 126 [28768/33609 (86%)]\tLoss: 16.329967\n","Train Epoch: 126 [31968/33609 (95%)]\tLoss: 18.363382\n","====> Epoch: 126 Average loss: 17.6931\n","Train Epoch: 127 [3168/33609 (9%)]\tLoss: 18.398193\n","Train Epoch: 127 [6368/33609 (19%)]\tLoss: 15.815181\n","Train Epoch: 127 [9568/33609 (28%)]\tLoss: 15.541843\n","Train Epoch: 127 [12768/33609 (38%)]\tLoss: 19.888119\n","Train Epoch: 127 [15968/33609 (47%)]\tLoss: 16.153538\n","Train Epoch: 127 [19168/33609 (57%)]\tLoss: 15.477262\n","Train Epoch: 127 [22368/33609 (67%)]\tLoss: 17.504921\n","Train Epoch: 127 [25568/33609 (76%)]\tLoss: 17.805685\n","Train Epoch: 127 [28768/33609 (86%)]\tLoss: 19.047363\n","Train Epoch: 127 [31968/33609 (95%)]\tLoss: 18.622049\n","====> Epoch: 127 Average loss: 17.6838\n","Train Epoch: 128 [3168/33609 (9%)]\tLoss: 17.281235\n","Train Epoch: 128 [6368/33609 (19%)]\tLoss: 17.262190\n","Train Epoch: 128 [9568/33609 (28%)]\tLoss: 19.971992\n","Train Epoch: 128 [12768/33609 (38%)]\tLoss: 15.739929\n","Train Epoch: 128 [15968/33609 (47%)]\tLoss: 21.477190\n","Train Epoch: 128 [19168/33609 (57%)]\tLoss: 14.639484\n","Train Epoch: 128 [22368/33609 (67%)]\tLoss: 16.483747\n","Train Epoch: 128 [25568/33609 (76%)]\tLoss: 17.453325\n","Train Epoch: 128 [28768/33609 (86%)]\tLoss: 15.291627\n","Train Epoch: 128 [31968/33609 (95%)]\tLoss: 17.098522\n","====> Epoch: 128 Average loss: 17.6670\n","Train Epoch: 129 [3168/33609 (9%)]\tLoss: 18.053577\n","Train Epoch: 129 [6368/33609 (19%)]\tLoss: 18.009632\n","Train Epoch: 129 [9568/33609 (28%)]\tLoss: 15.515343\n","Train Epoch: 129 [12768/33609 (38%)]\tLoss: 17.954004\n","Train Epoch: 129 [15968/33609 (47%)]\tLoss: 18.330690\n","Train Epoch: 129 [19168/33609 (57%)]\tLoss: 16.909327\n","Train Epoch: 129 [22368/33609 (67%)]\tLoss: 15.336539\n","Train Epoch: 129 [25568/33609 (76%)]\tLoss: 18.289307\n","Train Epoch: 129 [28768/33609 (86%)]\tLoss: 18.882250\n","Train Epoch: 129 [31968/33609 (95%)]\tLoss: 17.840528\n","====> Epoch: 129 Average loss: 17.6780\n","Train Epoch: 130 [3168/33609 (9%)]\tLoss: 18.450083\n","Train Epoch: 130 [6368/33609 (19%)]\tLoss: 18.694292\n","Train Epoch: 130 [9568/33609 (28%)]\tLoss: 17.187481\n","Train Epoch: 130 [12768/33609 (38%)]\tLoss: 19.697273\n","Train Epoch: 130 [15968/33609 (47%)]\tLoss: 17.946709\n","Train Epoch: 130 [19168/33609 (57%)]\tLoss: 17.844730\n","Train Epoch: 130 [22368/33609 (67%)]\tLoss: 19.121649\n","Train Epoch: 130 [25568/33609 (76%)]\tLoss: 16.266296\n","Train Epoch: 130 [28768/33609 (86%)]\tLoss: 18.088940\n","Train Epoch: 130 [31968/33609 (95%)]\tLoss: 19.933092\n","====> Epoch: 130 Average loss: 17.6831\n","Train Epoch: 131 [3168/33609 (9%)]\tLoss: 18.085192\n","Train Epoch: 131 [6368/33609 (19%)]\tLoss: 17.627476\n","Train Epoch: 131 [9568/33609 (28%)]\tLoss: 14.307861\n","Train Epoch: 131 [12768/33609 (38%)]\tLoss: 20.957727\n","Train Epoch: 131 [15968/33609 (47%)]\tLoss: 16.948118\n","Train Epoch: 131 [19168/33609 (57%)]\tLoss: 15.986740\n","Train Epoch: 131 [22368/33609 (67%)]\tLoss: 19.198097\n","Train Epoch: 131 [25568/33609 (76%)]\tLoss: 16.477278\n","Train Epoch: 131 [28768/33609 (86%)]\tLoss: 18.002903\n","Train Epoch: 131 [31968/33609 (95%)]\tLoss: 17.428656\n","====> Epoch: 131 Average loss: 17.6828\n","Train Epoch: 132 [3168/33609 (9%)]\tLoss: 19.707735\n","Train Epoch: 132 [6368/33609 (19%)]\tLoss: 18.264992\n","Train Epoch: 132 [9568/33609 (28%)]\tLoss: 18.128012\n","Train Epoch: 132 [12768/33609 (38%)]\tLoss: 14.542078\n","Train Epoch: 132 [15968/33609 (47%)]\tLoss: 16.239136\n","Train Epoch: 132 [19168/33609 (57%)]\tLoss: 15.664848\n","Train Epoch: 132 [22368/33609 (67%)]\tLoss: 16.607443\n","Train Epoch: 132 [25568/33609 (76%)]\tLoss: 14.915714\n","Train Epoch: 132 [28768/33609 (86%)]\tLoss: 17.474987\n","Train Epoch: 132 [31968/33609 (95%)]\tLoss: 18.893162\n","====> Epoch: 132 Average loss: 17.7041\n","Train Epoch: 133 [3168/33609 (9%)]\tLoss: 16.843033\n","Train Epoch: 133 [6368/33609 (19%)]\tLoss: 15.668924\n","Train Epoch: 133 [9568/33609 (28%)]\tLoss: 18.174953\n","Train Epoch: 133 [12768/33609 (38%)]\tLoss: 18.249456\n","Train Epoch: 133 [15968/33609 (47%)]\tLoss: 18.674841\n","Train Epoch: 133 [19168/33609 (57%)]\tLoss: 19.511724\n","Train Epoch: 133 [22368/33609 (67%)]\tLoss: 19.554598\n","Train Epoch: 133 [25568/33609 (76%)]\tLoss: 16.997417\n","Train Epoch: 133 [28768/33609 (86%)]\tLoss: 19.083340\n","Train Epoch: 133 [31968/33609 (95%)]\tLoss: 17.952337\n","====> Epoch: 133 Average loss: 17.6809\n","Train Epoch: 134 [3168/33609 (9%)]\tLoss: 16.508688\n","Train Epoch: 134 [6368/33609 (19%)]\tLoss: 16.340355\n","Train Epoch: 134 [9568/33609 (28%)]\tLoss: 17.813974\n","Train Epoch: 134 [12768/33609 (38%)]\tLoss: 20.483002\n","Train Epoch: 134 [15968/33609 (47%)]\tLoss: 17.074999\n","Train Epoch: 134 [19168/33609 (57%)]\tLoss: 18.330389\n","Train Epoch: 134 [22368/33609 (67%)]\tLoss: 14.714378\n","Train Epoch: 134 [25568/33609 (76%)]\tLoss: 20.185678\n","Train Epoch: 134 [28768/33609 (86%)]\tLoss: 18.708895\n","Train Epoch: 134 [31968/33609 (95%)]\tLoss: 16.266857\n","====> Epoch: 134 Average loss: 17.6857\n","Train Epoch: 135 [3168/33609 (9%)]\tLoss: 17.954659\n","Train Epoch: 135 [6368/33609 (19%)]\tLoss: 18.472830\n","Train Epoch: 135 [9568/33609 (28%)]\tLoss: 19.401264\n","Train Epoch: 135 [12768/33609 (38%)]\tLoss: 16.109646\n","Train Epoch: 135 [15968/33609 (47%)]\tLoss: 18.381889\n","Train Epoch: 135 [19168/33609 (57%)]\tLoss: 16.776871\n","Train Epoch: 135 [22368/33609 (67%)]\tLoss: 18.357235\n","Train Epoch: 135 [25568/33609 (76%)]\tLoss: 19.226454\n","Train Epoch: 135 [28768/33609 (86%)]\tLoss: 18.116747\n","Train Epoch: 135 [31968/33609 (95%)]\tLoss: 17.903881\n","====> Epoch: 135 Average loss: 17.6686\n","Train Epoch: 136 [3168/33609 (9%)]\tLoss: 14.077065\n","Train Epoch: 136 [6368/33609 (19%)]\tLoss: 19.679564\n","Train Epoch: 136 [9568/33609 (28%)]\tLoss: 21.156565\n","Train Epoch: 136 [12768/33609 (38%)]\tLoss: 17.795403\n","Train Epoch: 136 [15968/33609 (47%)]\tLoss: 18.173513\n","Train Epoch: 136 [19168/33609 (57%)]\tLoss: 20.651489\n","Train Epoch: 136 [22368/33609 (67%)]\tLoss: 15.890515\n","Train Epoch: 136 [25568/33609 (76%)]\tLoss: 19.210588\n","Train Epoch: 136 [28768/33609 (86%)]\tLoss: 19.632874\n","Train Epoch: 136 [31968/33609 (95%)]\tLoss: 19.033701\n","====> Epoch: 136 Average loss: 17.6977\n","Train Epoch: 137 [3168/33609 (9%)]\tLoss: 19.372778\n","Train Epoch: 137 [6368/33609 (19%)]\tLoss: 16.063721\n","Train Epoch: 137 [9568/33609 (28%)]\tLoss: 19.097855\n","Train Epoch: 137 [12768/33609 (38%)]\tLoss: 16.820963\n","Train Epoch: 137 [15968/33609 (47%)]\tLoss: 17.063877\n","Train Epoch: 137 [19168/33609 (57%)]\tLoss: 17.002338\n","Train Epoch: 137 [22368/33609 (67%)]\tLoss: 19.077671\n","Train Epoch: 137 [25568/33609 (76%)]\tLoss: 20.401751\n","Train Epoch: 137 [28768/33609 (86%)]\tLoss: 18.234808\n","Train Epoch: 137 [31968/33609 (95%)]\tLoss: 17.716106\n","====> Epoch: 137 Average loss: 17.6719\n","Train Epoch: 138 [3168/33609 (9%)]\tLoss: 18.588615\n","Train Epoch: 138 [6368/33609 (19%)]\tLoss: 18.289032\n","Train Epoch: 138 [9568/33609 (28%)]\tLoss: 17.934025\n","Train Epoch: 138 [12768/33609 (38%)]\tLoss: 16.845966\n","Train Epoch: 138 [15968/33609 (47%)]\tLoss: 18.427097\n","Train Epoch: 138 [19168/33609 (57%)]\tLoss: 16.202957\n","Train Epoch: 138 [22368/33609 (67%)]\tLoss: 19.050562\n","Train Epoch: 138 [25568/33609 (76%)]\tLoss: 18.234745\n","Train Epoch: 138 [28768/33609 (86%)]\tLoss: 16.857637\n","Train Epoch: 138 [31968/33609 (95%)]\tLoss: 18.755194\n","====> Epoch: 138 Average loss: 17.6559\n","Train Epoch: 139 [3168/33609 (9%)]\tLoss: 16.984451\n","Train Epoch: 139 [6368/33609 (19%)]\tLoss: 17.546047\n","Train Epoch: 139 [9568/33609 (28%)]\tLoss: 17.630766\n","Train Epoch: 139 [12768/33609 (38%)]\tLoss: 18.053566\n","Train Epoch: 139 [15968/33609 (47%)]\tLoss: 16.444454\n","Train Epoch: 139 [19168/33609 (57%)]\tLoss: 15.684687\n","Train Epoch: 139 [22368/33609 (67%)]\tLoss: 18.953201\n","Train Epoch: 139 [25568/33609 (76%)]\tLoss: 17.167685\n","Train Epoch: 139 [28768/33609 (86%)]\tLoss: 17.817102\n","Train Epoch: 139 [31968/33609 (95%)]\tLoss: 18.635818\n","====> Epoch: 139 Average loss: 17.6714\n","Train Epoch: 140 [3168/33609 (9%)]\tLoss: 16.360085\n","Train Epoch: 140 [6368/33609 (19%)]\tLoss: 18.860092\n","Train Epoch: 140 [9568/33609 (28%)]\tLoss: 20.687332\n","Train Epoch: 140 [12768/33609 (38%)]\tLoss: 19.371002\n","Train Epoch: 140 [15968/33609 (47%)]\tLoss: 16.455132\n","Train Epoch: 140 [19168/33609 (57%)]\tLoss: 17.890030\n","Train Epoch: 140 [22368/33609 (67%)]\tLoss: 21.553421\n","Train Epoch: 140 [25568/33609 (76%)]\tLoss: 17.651802\n","Train Epoch: 140 [28768/33609 (86%)]\tLoss: 16.905926\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9ulksoiR579D"},"source":[""],"execution_count":null,"outputs":[]}]}